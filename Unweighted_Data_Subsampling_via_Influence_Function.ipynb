{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8JsMrkCrYw3"
      },
      "source": [
        "## **Basic imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aIh_f_kK1G_g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy import sparse\n",
        "import sys\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "\n",
        "sys.path.append(\"..\")\n",
        "from inverse_hvp import inverse_hvp_lr_newtonCG\n",
        "import argparse\n",
        "import time\n",
        "import pdb\n",
        "import os\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AdBdltarAyJ"
      },
      "source": [
        "# 1. **MNIST Dataset Load and Preprocessing the data in required format**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CV4aHBR41G_x"
      },
      "outputs": [],
      "source": [
        "# select the dataset used\n",
        "dataset_name = \"mnist\"\n",
        "# regularization parameter for Logistic Regression\n",
        "C = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOGuUulj3n4h",
        "outputId": "dd8d0905-9da0-40ab-ad1e-33d1352dbc8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting train-images-idx3-ubyte.gz\n",
            "Extracting train-labels-idx1-ubyte.gz\n",
            "Extracting t10k-images-idx3-ubyte.gz\n",
            "Extracting t10k-labels-idx1-ubyte.gz\n",
            "x_train, nr sample 8325, nr feature 784\n",
            "x_va,    nr sample 3569, nr feature 784\n",
            "x_te,    nr sample 2163, nr feature 784\n",
            "Tr: Pos 4395 Neg 3930\n",
            "Va: Pos 1784 Neg 1785\n",
            "Te: Pos 1135 Neg 1028\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# tool box\n",
        "def load_mnist(validation_size = 5000):\n",
        "    import gzip\n",
        "    def _read32(bytestream):\n",
        "        dt = np.dtype(np.uint32).newbyteorder(\">\")\n",
        "        return np.frombuffer(bytestream.read(4),dtype=dt)[0]\n",
        "\n",
        "    def extract_images(f):\n",
        "        print(\"Extracting\",f.name)\n",
        "        with gzip.GzipFile(fileobj=f) as bytestream:\n",
        "            magic = _read32(bytestream)\n",
        "            num_images = _read32(bytestream)\n",
        "            rows = _read32(bytestream)\n",
        "            cols = _read32(bytestream)\n",
        "            buf = bytestream.read(rows * cols * num_images)\n",
        "            data = np.frombuffer(buf,dtype=np.uint8)\n",
        "            data = data.reshape(num_images,rows,cols,1)\n",
        "            return data\n",
        "    \n",
        "    def extract_labels(f):\n",
        "        print('Extracting', f.name)\n",
        "        with gzip.GzipFile(fileobj=f) as bytestream:\n",
        "            magic = _read32(bytestream)\n",
        "            num_items = _read32(bytestream)\n",
        "            buf = bytestream.read(num_items)\n",
        "            labels = np.frombuffer(buf, dtype=np.uint8)\n",
        "            return labels\n",
        "\n",
        "    #data_dir = \"./data\"\n",
        "    data_dir = \"\"\n",
        "    TRAIN_IMAGES = os.path.join(data_dir,'train-images-idx3-ubyte.gz')\n",
        "    with open(TRAIN_IMAGES,\"rb\") as f:\n",
        "        train_images = extract_images(f)\n",
        "\n",
        "    TRAIN_LABELS =  os.path.join(data_dir,'train-labels-idx1-ubyte.gz')\n",
        "    with open(TRAIN_LABELS,\"rb\") as f:\n",
        "        train_labels = extract_labels(f)\n",
        "\n",
        "    TEST_IMAGES =  os.path.join(data_dir,'t10k-images-idx3-ubyte.gz')\n",
        "    with open(TEST_IMAGES,\"rb\") as f:\n",
        "        test_images = extract_images(f)\n",
        "\n",
        "    TEST_LABELS =  os.path.join(data_dir,'t10k-labels-idx1-ubyte.gz')\n",
        "    with open(TEST_LABELS,\"rb\") as f:\n",
        "        test_labels = extract_labels(f)\n",
        "\n",
        "    # split train and val\n",
        "    train_images = train_images[validation_size:]\n",
        "    train_labels = train_labels[validation_size:]\n",
        "\n",
        "    # preprocessing\n",
        "    train_images = train_images.astype(np.float32) / 255\n",
        "    test_images  = test_images.astype(np.float32) / 255\n",
        "    \n",
        "    # reshape for logistic regression\n",
        "    train_images = np.reshape(train_images, [train_images.shape[0], -1])\n",
        "    test_images = np.reshape(test_images, [test_images.shape[0], -1])\n",
        "    return train_images,train_labels,test_images,test_labels\n",
        "\n",
        "def load_data_two_class(dataset_name,va_ratio):\n",
        "  x_train,y_train,x_test,y_test = load_mnist()\n",
        "  pos_class = 1\n",
        "  neg_class = 7\n",
        "  x_train,y_train = filter_dataset(x_train,y_train,pos_class,neg_class)\n",
        "  x_va,y_va = filter_dataset(x_test,y_test,pos_class,neg_class)\n",
        "  y_va = y_va.astype(int)\n",
        "  y_train = y_train.astype(int)\n",
        "\n",
        "  num_va_sample = int((1-va_ratio) * x_train.shape[0])\n",
        "  x_val = x_train[num_va_sample:]\n",
        "  y_val = y_train[num_va_sample:]\n",
        "  x_train = x_train[:num_va_sample]\n",
        "  y_train = y_train[:num_va_sample]\n",
        "  x_te = x_va\n",
        "  y_te = y_va\n",
        "\n",
        "  return x_train,y_train,x_val,y_val,x_te,y_te\n",
        "\n",
        "\n",
        "def filter_dataset(X, Y, pos_class, neg_class, mode=None):\n",
        "    \n",
        "    \"\"\"\n",
        "    Filters out elements of X and Y that aren't one of pos_class or neg_class\n",
        "    then transforms labels of Y so that +1 = pos_class, -1 = neg_class.\n",
        "\n",
        "    They are all 10-classes image classification data sets while Logistic regression can only handle binary classification. we\n",
        "    select the number 1 and 7 as positive and negative classes;\n",
        "    \"\"\"\n",
        "\n",
        "    assert(X.shape[0] == Y.shape[0])\n",
        "    assert(len(Y.shape) == 1)\n",
        "\n",
        "    Y = Y.astype(int)\n",
        "    \n",
        "    pos_idx = Y == pos_class\n",
        "    neg_idx = Y == neg_class        \n",
        "    Y[pos_idx] = 1\n",
        "    Y[neg_idx] = -1\n",
        "    idx_to_keep = pos_idx | neg_idx\n",
        "    X = X[idx_to_keep, ...]\n",
        "    Y = Y[idx_to_keep]\n",
        "    if Y.min() == -1 and mode != \"svm\":\n",
        "        Y = (Y + 1) / 2\n",
        "        Y.astype(int)\n",
        "    return (X, Y)\n",
        "\n",
        "# load data, pick 30% as the Va set\n",
        "x_train,y_train,x_va,y_va,x_te,y_te = load_data_two_class(dataset_name,va_ratio=0.3)\n",
        "\n",
        "\n",
        "\n",
        "print(\"x_train, nr sample {}, nr feature {}\".format(x_train.shape[0],x_train.shape[1]))\n",
        "print(\"x_va,    nr sample {}, nr feature {}\".format(x_va.shape[0],x_va.shape[1]))\n",
        "print(\"x_te,    nr sample {}, nr feature {}\".format(x_te.shape[0],x_te.shape[1]))\n",
        "print(\"Tr: Pos {} Neg {}\".format(y_train[y_train==1].shape[0],y_train[y_train==0].shape[0]))\n",
        "print(\"Va: Pos {} Neg {}\".format(y_va[y_va==1].shape[0],y_va[y_va==0].shape[0]))\n",
        "print(\"Te: Pos {} Neg {}\".format(y_te[y_te==1].shape[0],y_te[y_te==0].shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIS_ygsKtHM2"
      },
      "source": [
        "# 2. **Flip labels for some of the images to make the data noisy so that we can show how our method discrad these kind of noisy data hence flipping the labels of some data in below code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KZ26meoM1HAF"
      },
      "outputs": [],
      "source": [
        "# get the subset samples number\n",
        "num_tr_sample = x_train.shape[0]\n",
        "sample_ratio = 0.6\n",
        "obj_sample_size = int(sample_ratio * num_tr_sample)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "# Our unweighted method can downweight the bad cases which cause high test loss to the our model, which is an important reason of its ability to improve result with less data.\n",
        "To show the performance of our methods in noisy label situation, we perform addtional experiments with some training\n",
        "labels being flipped. The results show the enlarging superiority of our subsampling methods \n",
        "\"\"\"\n",
        "\n",
        "# flip labels\n",
        "idxs = np.arange(y_train.shape[0])\n",
        "flip_ratio = 0.4\n",
        "np.random.shuffle(idxs)\n",
        "num_flip = int(flip_ratio * len(idxs))\n",
        "y_train[idxs[:num_flip]] = np.logical_xor(np.ones(num_flip), y_train[idxs[:num_flip]]).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65j1_ru2txsq"
      },
      "source": [
        "# 3. **Training model on the full data set (ˆθ on the full Tr)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvhPW3cFtx89",
        "outputId": "f1d95a8b-d2b2-4e82-dc79-9cee9d8e41ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LibLinear]iter  1 act 1.784e+01 pre 1.766e+01 delta 2.238e-01 f 5.770e+02 |g| 2.249e+02 CG   4\n",
            "cg reaches trust region boundary\n",
            "iter  2 act 1.948e+00 pre 1.946e+00 delta 2.357e-01 f 5.592e+02 |g| 2.199e+01 CG   4\n",
            "cg reaches trust region boundary\n",
            "iter  3 act 2.042e+00 pre 2.040e+00 delta 3.111e-01 f 5.573e+02 |g| 2.639e+01 CG   5\n",
            "cg reaches trust region boundary\n",
            "iter  4 act 1.871e+00 pre 1.869e+00 delta 4.825e-01 f 5.552e+02 |g| 1.447e+01 CG   5\n",
            "cg reaches trust region boundary\n",
            "iter  5 act 1.743e+00 pre 1.738e+00 delta 5.484e-01 f 5.533e+02 |g| 1.329e+01 CG   6\n",
            "cg reaches trust region boundary\n",
            "iter  6 act 1.800e+00 pre 1.791e+00 delta 6.828e-01 f 5.516e+02 |g| 1.205e+01 CG   7\n",
            "cg reaches trust region boundary\n",
            "iter  7 act 1.148e+00 pre 1.147e+00 delta 7.735e-01 f 5.498e+02 |g| 1.293e+01 CG   8\n",
            "iter  8 act 5.453e-01 pre 5.448e-01 delta 7.735e-01 f 5.487e+02 |g| 5.447e+00 CG  16\n",
            "iter  9 act 1.441e-02 pre 1.441e-02 delta 7.735e-01 f 5.481e+02 |g| 5.371e-01 CG  25\n",
            "iter 10 act 1.435e-04 pre 1.435e-04 delta 7.735e-01 f 5.481e+02 |g| 4.869e-02 CG  27\n",
            "iter 11 act 7.211e-07 pre 7.211e-07 delta 7.735e-01 f 5.481e+02 |g| 4.112e-03 CG  25\n",
            "iter 12 act 7.139e-09 pre 7.136e-09 delta 7.735e-01 f 5.481e+02 |g| 3.614e-04 CG  27\n",
            "iter 13 act 3.251e-11 pre 3.545e-11 delta 7.735e-01 f 5.481e+02 |g| 3.199e-05 CG  23\n",
            "WARNING: actred and prered too small\n",
            "[FullSet] Va logloss 0.525831\n",
            "[FullSet] Te logloss 0.522210\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# define the full-set-model \n",
        "\n",
        "\"\"\" \n",
        "model : logistic regression:\n",
        "C: Inverse of regularization strength. smaller values specify stronger regularization.\n",
        "fit_intercept: constant (a.k.a. bias or intercept) should be added to the decision function.\n",
        "tol: Tolerance for stopping criteria.\n",
        "solver: Algorithm to use in the optimization problem.For small datasets, ‘liblinear’ is a good choice\n",
        "multi_class: ‘ovr’, then a binary problem is fit for each label.\n",
        "max_iterint: Maximum number of iterations taken for the solvers to converge\n",
        "\"\"\"\n",
        "\n",
        "clf = LogisticRegression(\n",
        "        C = C,\n",
        "        fit_intercept=False,\n",
        "        tol = 1e-8,\n",
        "        solver=\"liblinear\",\n",
        "        multi_class=\"ovr\",\n",
        "        max_iter=100,\n",
        "        warm_start=False,\n",
        "        verbose=1,\n",
        "        )\n",
        "\n",
        "clf.fit(x_train,y_train)\n",
        "\n",
        "# on Va\n",
        "\n",
        "y_va_pred = clf.predict_proba(x_va)[:,1] \n",
        "#predict_proba : Probability estimates. The returned estimates for all classes are ordered by the label of classes.\n",
        "full_logloss = log_loss(y_va,y_va_pred) \n",
        "#Log loss, aka logistic loss or cross-entropy loss. This is the loss function defined as the negative log-likelihood of a logistic model that returns y_pred probabilities for its training data y_true. \n",
        "#For a single sample with true label yt in {0,1} and estimated probability yp that yt = 1, the log loss is\n",
        "#-log P(yt|yp) = -(yt log(yp) + (1 - yt) log(1 - yp))\n",
        "weight_ar = clf.coef_.flatten() \n",
        "#Coefficient of the features in the decision function. coef_ is of shape (1, n_features) when the given problem is binary.\n",
        "\n",
        "# on Te\n",
        "\n",
        "y_te_pred = clf.predict_proba(x_te)[:,1]\n",
        "full_te_logloss = log_loss(y_te,y_te_pred)\n",
        "full_te_auc = roc_auc_score(y_te, y_te_pred)\n",
        "#The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.\n",
        "# The true-positive rate is also known as sensitivity, recall or probability of detection\n",
        "# The false-positive rate is also known as probability of false alarm \n",
        "# AUC measures how true positive rate (recall) and false positive rate trade off\n",
        "\n",
        "y_te_pred = clf.predict(x_te)\n",
        "full_te_acc = (y_te == y_te_pred).sum() / y_te.shape[0]\n",
        "\n",
        "\n",
        "# print full-set-model results\n",
        "print(\"[FullSet] Va logloss {:.6f}\".format(full_logloss))\n",
        "print(\"[FullSet] Te logloss {:.6f}\".format(full_te_logloss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ5h8v3kTwrh"
      },
      "source": [
        "# 4. **compute the influence function (IF) for each sample in training set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UeP4tgowUNvS"
      },
      "outputs": [],
      "source": [
        "def grad_logloss_theta_lr(label,ypred,x,C=0.03,has_l2=True,scale_factor=1.0):\n",
        "    \"\"\"Return d l_i / d_theta = d l_i / d_ypred * d y_pred / d theta\n",
        "        grad_logloss_theta: gradient on the theta, shape: [n,]\n",
        "    \"\"\"\n",
        "    # The isinstance() function returns True if the specified object is of the specified type, otherwise False.\n",
        "    if not isinstance(label,np.ndarray) or not isinstance(ypred,np.ndarray):\n",
        "        label = np.array(label).flatten()\n",
        "        ypred = np.array(ypred).flatten()\n",
        "\n",
        "\n",
        "    grad_logloss_theta = C * x.T.dot(ypred-label)\n",
        "\n",
        "    return scale_factor * grad_logloss_theta\n",
        "\n",
        "def batch_grad_logloss_lr(label,ypred,x,C=0.03,scale_factor=1.0):\n",
        "    \"\"\"Return gradient on a batch.\n",
        "        batch_grad: gradient of each sample on parameters,\n",
        "            has shape [None,n]\n",
        "    \"\"\"\n",
        "    diffs = ypred - label\n",
        "    if isinstance(x,np.ndarray):\n",
        "        diffs = diffs.reshape(-1,1)\n",
        "        batch_grad = x * diffs\n",
        "    else:\n",
        "        diffs = sparse.diags(diffs)\n",
        "        batch_grad = x.T.dot(diffs).T\n",
        "    batch_grad = sparse.csr_matrix(C * batch_grad)      \n",
        "    return scale_factor * batch_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IhBwAgki1HAU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8325, 784)\n",
            "(8325,)\n",
            "(8325,)\n",
            "(784,)\n",
            "0.1\n",
            "(784,)\n",
            "0.00012012012012012013\n",
            "Succeed in getting the inverse of preconditioner M.\n",
            "iter 0 cg iter 0 iter_diff 4305.735512646801\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/pnans/Documents/GitHub/Unweighted-Data-Subsampling-via-Influence-Function/inverse_hvp.py:146: OptimizeWarning: Unknown solver options: preconditioner\n",
            "  fmin_results = fmin_ncg(f=fmin_loss_fn,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function value: -360480.4532690004\n",
            "Split function value: 363857.5355531955, -724337.9888221959\n",
            "iter 1 cg iter 0 iter_diff 994.9107666369654\n",
            "Function value: -402211.57174907194\n",
            "Split function value: 372196.4301940192, -774408.0019430912\n",
            "iter 2 cg iter 0 iter_diff 480.3468302419942\n",
            "Function value: -437606.79833226895\n",
            "Split function value: 439776.61213072226, -877383.4104629912\n",
            "iter 3 cg iter 0 iter_diff 203.96676376517718\n",
            "iter 3 cg iter 10 iter_diff 103.06986903307417\n",
            "Function value: -469177.5246129272\n",
            "Split function value: 476194.82317021757, -945372.3477831448\n",
            "iter 4 cg iter 0 iter_diff 79.42536795709998\n",
            "iter 4 cg iter 10 iter_diff 46.498857427336254\n",
            "Function value: -475866.23644338455\n",
            "Split function value: 465757.77973365155, -941624.0161770361\n",
            "iter 5 cg iter 0 iter_diff 33.34395773833848\n",
            "iter 5 cg iter 10 iter_diff 16.0987010186897\n",
            "Function value: -476560.76464876404\n",
            "Split function value: 473982.8922486623, -950543.6568974264\n",
            "iter 6 cg iter 0 iter_diff 16.098701018689077\n",
            "iter 6 cg iter 10 iter_diff 10.339522391149817\n",
            "Function value: -476817.94054725685\n",
            "Split function value: 476369.62417307135, -953187.5647203282\n",
            "iter 7 cg iter 0 iter_diff 5.8069878465661855\n",
            "Function value: -476835.51161267306\n",
            "Split function value: 476488.94168038666, -953324.4532930597\n",
            "iter 8 cg iter 0 iter_diff 2.207735779429986\n",
            "iter 8 cg iter 10 iter_diff 2.2667747643270237\n",
            "Function value: -476841.3134901144\n",
            "Split function value: 476897.10139419185, -953738.4148843063\n",
            "iter 9 cg iter 0 iter_diff 1.0570202251841785\n",
            "iter 9 cg iter 10 iter_diff 0.48117183730579327\n",
            "Function value: -476842.2813511372\n",
            "Split function value: 476761.99276343803, -953604.2741145752\n",
            "iter 10 cg iter 0 iter_diff 0.4811718373069077\n",
            "iter 10 cg iter 10 iter_diff 0.36347655073304075\n",
            "Function value: -476842.65113994473\n",
            "Split function value: 476862.51510785293, -953705.1662477977\n",
            "iter 11 cg iter 0 iter_diff 0.19879928522084192\n",
            "Function value: -476842.6665751763\n",
            "Split function value: 476848.6729853306, -953691.3395605069\n",
            "iter 12 cg iter 0 iter_diff 0.07384474105934571\n",
            "iter 12 cg iter 10 iter_diff 0.033391345950662815\n",
            "Function value: -476842.6725223932\n",
            "Split function value: 476840.8637468419, -953683.5362692351\n",
            "iter 13 cg iter 0 iter_diff 0.017922565293669007\n",
            "iter 13 cg iter 10 iter_diff 0.021166967018107743\n",
            "iter 13 cg iter 20 iter_diff 0.003109780931759696\n",
            "Function value: -476842.6731416618\n",
            "Split function value: 476842.43528704764, -953685.1084287094\n",
            "iter 14 cg iter 0 iter_diff 0.00146866034242501\n",
            "iter 14 cg iter 10 iter_diff 0.00044819104212612525\n",
            "iter 14 cg iter 20 iter_diff 0.0003501297024604792\n",
            "Function value: -476842.67314456776\n",
            "Split function value: 476842.67331056437, -953685.3464551321\n",
            "iter 15 cg iter 0 iter_diff 4.101644814237675e-05\n",
            "iter 15 cg iter 10 iter_diff 1.6946023245622383e-05\n",
            "iter 15 cg iter 20 iter_diff 1.1025520516437915e-05\n",
            "Function value: -476842.6731445708\n",
            "Split function value: 476842.67337663425, -953685.346521205\n",
            "iter 16 cg iter 0 iter_diff 6.044899767364521e-06\n",
            "iter 16 cg iter 10 iter_diff 3.6240777932306504e-06\n",
            "Function value: -476842.673144571\n",
            "Split function value: 476842.6732926832, -953685.3464372542\n",
            "Optimization terminated successfully.\n",
            "         Current function value: -476842.673145\n",
            "         Iterations: 17\n",
            "         Function evaluations: 81\n",
            "         Gradient evaluations: 94\n",
            "         Hessian evaluations: 211\n",
            "Inverse HVP took 21.1 sec\n",
            "============================================================\n",
            "IF(influence function) Stats: mean -1.3193588941, max 748.7852101516, min -983.3977022934\n"
          ]
        }
      ],
      "source": [
        "# building precoditioner\n",
        "test_grad_loss_val = grad_logloss_theta_lr(y_va,y_va_pred,x_va,C,0.1/(num_tr_sample*C))  #Return d l_i / d_theta\n",
        "\n",
        "tr_pred = clf.predict_proba(x_train)[:,1]\n",
        "batch_size = 10000\n",
        "M = None\n",
        "total_batch = int(np.ceil(num_tr_sample / float(batch_size)))\n",
        "\n",
        "for idx in range(total_batch):\n",
        "    batch_tr_grad = batch_grad_logloss_lr(y_train[idx*batch_size:(idx+1)*batch_size],\n",
        "        tr_pred[idx*batch_size:(idx+1)*batch_size],\n",
        "        x_train[idx*batch_size:(idx+1)*batch_size],\n",
        "        C,\n",
        "        1.0)\n",
        "\n",
        "    sum_grad = batch_tr_grad.multiply(x_train[idx*batch_size:(idx+1)*batch_size]).sum(0)\n",
        "    if M is None:\n",
        "        M = sum_grad\n",
        "    else:\n",
        "        M = M + sum_grad       \n",
        "M = M + 0.1/(num_tr_sample*C) * np.ones(x_train.shape[1])\n",
        "M = np.array(M).flatten()\n",
        "\n",
        "# computing the inverse Hessian-vector-product\n",
        "#The Hessian Matrix is a square matrix of second ordered partial derivatives of a scalar function.\n",
        "#It is of immense use in linear algebra as well as for determining points of local maxima or minima\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(tr_pred.shape)\n",
        "print(test_grad_loss_val.shape)\n",
        "print(C)\n",
        "print(M.shape)\n",
        "print(0.1/(num_tr_sample*C))\n",
        "\n",
        "\n",
        "iv_hvp = inverse_hvp_lr_newtonCG(x_train,y_train,tr_pred,test_grad_loss_val,C,True,1e-5,True,M,0.1/(num_tr_sample*C))\n",
        "\n",
        "# get influence score\n",
        "total_batch = int(np.ceil(x_train.shape[0] / float(batch_size)))\n",
        "predicted_loss_diff = []\n",
        "for idx in range(total_batch):\n",
        "    train_grad_loss_val = batch_grad_logloss_lr(y_train[idx*batch_size:(idx+1)*batch_size],\n",
        "        tr_pred[idx*batch_size:(idx+1)*batch_size],\n",
        "        x_train[idx*batch_size:(idx+1)*batch_size],\n",
        "        C,\n",
        "        1.0)\n",
        "    predicted_loss_diff.extend(np.array(train_grad_loss_val.dot(iv_hvp)).flatten())    \n",
        "predicted_loss_diffs = np.asarray(predicted_loss_diff)\n",
        "\n",
        "print(\"==\"*30)\n",
        "print(\"IF(influence function) Stats: mean {:.10f}, max {:.10f}, min {:.10f}\".format(\n",
        "    predicted_loss_diffs.mean(), predicted_loss_diffs.max(), predicted_loss_diffs.min())\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACmwNiFGmlJG"
      },
      "source": [
        "# **5.compute the sampling probability of each sample in training set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "RBSf9aEgm1mb"
      },
      "outputs": [],
      "source": [
        "def select_from_one_class(y_train,prob_pi,label,ratio):\n",
        "    # select positive and negative samples respectively\n",
        "    num_sample = y_train[y_train==label].shape[0]\n",
        "    all_idx = np.arange(y_train.shape[0])[y_train==label]\n",
        "    label_prob_pi = prob_pi[all_idx]\n",
        "    obj_sample_size = int(ratio * num_sample)\n",
        "\n",
        "    sb_idx = None\n",
        "    iteration = 0\n",
        "    while True:\n",
        "        rand_prob = np.random.rand(num_sample)\n",
        "        iter_idx = all_idx[rand_prob < label_prob_pi]\n",
        "        if sb_idx is None:\n",
        "            sb_idx = iter_idx\n",
        "        else:\n",
        "            new_idx = np.setdiff1d(iter_idx, sb_idx)\n",
        "            diff_size = obj_sample_size - sb_idx.shape[0]\n",
        "            if new_idx.shape[0] < diff_size:\n",
        "                sb_idx = np.union1d(iter_idx, sb_idx)\n",
        "            else:\n",
        "                new_idx = np.random.choice(new_idx, diff_size, replace=False)\n",
        "                sb_idx = np.union1d(sb_idx, new_idx)\n",
        "        iteration += 1\n",
        "        if sb_idx.shape[0] >= obj_sample_size:\n",
        "            sb_idx = np.random.choice(sb_idx,obj_sample_size,replace=False)\n",
        "            return sb_idx\n",
        "\n",
        "        if iteration > 100:\n",
        "            diff_size = obj_sample_size - sb_idx.shape[0]\n",
        "            leave_idx = np.setdiff1d(all_idx, sb_idx)\n",
        "            # left samples are sorted by their IF\n",
        "            # leave_idx = leave_idx[np.argsort(prob_pi[leave_idx])[-diff_size:]]\n",
        "            leave_idx = np.random.choice(leave_idx,diff_size,replace=False)\n",
        "            sb_idx = np.union1d(sb_idx, leave_idx)\n",
        "            return sb_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZND6k2RY1HAf",
        "outputId": "904bf4b3-964b-4903-99fb-92a506dc0beb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pi Stats: [0.08010065 0.1627333  0.66298381 0.79176391 0.8593959 ]\n"
          ]
        }
      ],
      "source": [
        "# build sampling probability\n",
        "\n",
        "sigmoid_k = 10  # parameter for the sigmoid sampling function\n",
        "phi_ar = - predicted_loss_diffs\n",
        "IF_interval = phi_ar.max() - phi_ar.min()\n",
        "a_param = sigmoid_k / IF_interval\n",
        "prob_pi = 1 / (1 + np.exp(a_param * phi_ar))\n",
        "print(\"Pi Stats:\",np.percentile(prob_pi,[10,25,50,75,90]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJQYsVTynHWT"
      },
      "source": [
        "# **6. Do subsampling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "qThZ8V7snHvD"
      },
      "outputs": [],
      "source": [
        "pos_idx = select_from_one_class(y_train,prob_pi,1,sample_ratio)\n",
        "neg_idx = select_from_one_class(y_train,prob_pi,0,sample_ratio)\n",
        "sb_idx = np.union1d(pos_idx,neg_idx)\n",
        "sb_x_train = x_train[sb_idx]\n",
        "sb_y_train = y_train[sb_idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYgx4f4lnVXo"
      },
      "source": [
        "# **7. train a subset-model on the reduced data set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xTdpYUwnVgo",
        "outputId": "ec68939a-facb-4f8c-d323-e170900c5361"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LibLinear]iter  1 act 1.246e+02 pre 1.145e+02 delta 5.750e-01 f 3.462e+02 |g| 4.817e+02 CG   3\n",
            "cg reaches trust region boundary\n",
            "iter  2 act 1.454e+01 pre 1.312e+01 delta 6.991e-01 f 2.216e+02 |g| 8.830e+01 CG   4\n",
            "cg reaches trust region boundary\n",
            "iter  3 act 4.924e+00 pre 4.722e+00 delta 8.327e-01 f 2.070e+02 |g| 2.178e+01 CG   4\n",
            "cg reaches trust region boundary\n",
            "iter  4 act 3.154e+00 pre 3.148e+00 delta 9.560e-01 f 2.021e+02 |g| 1.198e+01 CG   5\n",
            "cg reaches trust region boundary\n",
            "iter  5 act 2.026e+00 pre 1.978e+00 delta 1.016e+00 f 1.990e+02 |g| 7.115e+00 CG   7\n",
            "iter  6 act 8.089e-01 pre 8.088e-01 delta 1.016e+00 f 1.969e+02 |g| 4.989e+00 CG  13\n",
            "iter  7 act 1.580e-02 pre 1.578e-02 delta 1.016e+00 f 1.961e+02 |g| 8.397e-01 CG  14\n",
            "iter  8 act 3.571e-04 pre 3.571e-04 delta 1.016e+00 f 1.961e+02 |g| 6.139e-02 CG  18\n",
            "iter  9 act 1.186e-06 pre 1.186e-06 delta 1.016e+00 f 1.961e+02 |g| 5.604e-03 CG  14\n",
            "iter 10 act 2.320e-08 pre 2.320e-08 delta 1.016e+00 f 1.961e+02 |g| 5.316e-04 CG  16\n",
            "iter 11 act 1.363e-10 pre 1.357e-10 delta 1.016e+00 f 1.961e+02 |g| 4.436e-05 CG  16\n",
            "WARNING: actred and prered too small\n"
          ]
        }
      ],
      "source": [
        "clf.fit(sb_x_train,sb_y_train)\n",
        "y_va_pred = clf.predict_proba(x_va)[:,1]\n",
        "sb_logloss = log_loss(y_va, y_va_pred)\n",
        "sb_weight = clf.coef_.flatten()\n",
        "diff_w_norm = np.linalg.norm(weight_ar - sb_weight)\n",
        "sb_size = sb_x_train.shape[0]\n",
        "y_te_pred = clf.predict_proba(x_te)[:,1]\n",
        "sb_te_logloss = log_loss(y_te,y_te_pred)\n",
        "sb_te_auc = roc_auc_score(y_te, y_te_pred)\n",
        "y_te_pred = clf.predict(x_te)\n",
        "sb_te_acc = (y_te == y_te_pred).sum() / y_te.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZgVvIwhniJ2"
      },
      "source": [
        "## **For comparison doing general method of subsampling i.e random subsampling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns02r4Ldnhjm",
        "outputId": "37961b9e-9d29-4813-9fe6-479c0d9a384b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LibLinear]iter  1 act 1.276e+01 pre 1.258e+01 delta 4.898e-01 f 3.462e+02 |g| 1.361e+02 CG   5\n",
            "cg reaches trust region boundary\n",
            "iter  2 act 2.358e+00 pre 2.373e+00 delta 5.391e-01 f 3.335e+02 |g| 1.261e+01 CG   5\n",
            "cg reaches trust region boundary\n",
            "iter  3 act 2.198e+00 pre 2.183e+00 delta 6.885e-01 f 3.311e+02 |g| 1.069e+01 CG   6\n",
            "cg reaches trust region boundary\n",
            "iter  4 act 1.393e+00 pre 1.391e+00 delta 7.241e-01 f 3.289e+02 |g| 6.927e+00 CG   7\n",
            "cg reaches trust region boundary\n",
            "iter  5 act 1.037e+00 pre 1.031e+00 delta 7.585e-01 f 3.275e+02 |g| 7.856e+00 CG   9\n",
            "iter  6 act 2.424e-01 pre 2.424e-01 delta 7.585e-01 f 3.265e+02 |g| 4.735e+00 CG  14\n",
            "iter  7 act 7.395e-03 pre 7.395e-03 delta 7.585e-01 f 3.262e+02 |g| 3.683e-01 CG  20\n",
            "iter  8 act 5.608e-05 pre 5.608e-05 delta 7.585e-01 f 3.262e+02 |g| 3.337e-02 CG  22\n",
            "iter  9 act 3.056e-07 pre 3.056e-07 delta 7.585e-01 f 3.262e+02 |g| 2.430e-03 CG  19\n",
            "iter 10 act 4.799e-09 pre 4.799e-09 delta 7.585e-01 f 3.262e+02 |g| 2.403e-04 CG  21\n",
            "iter 11 act 2.581e-11 pre 2.438e-11 delta 7.585e-01 f 3.262e+02 |g| 2.216e-05 CG  18\n",
            "WARNING: actred and prered too small\n"
          ]
        }
      ],
      "source": [
        "# baseline model: random sampling\n",
        "\n",
        "u_idxs = np.arange(x_train.shape[0])\n",
        "uniform_idxs = np.random.choice(u_idxs,obj_sample_size,replace=False)\n",
        "us_x_train = x_train[uniform_idxs]\n",
        "us_y_train = y_train[uniform_idxs]\n",
        "clf.fit(us_x_train, us_y_train)\n",
        "y_va_pred = clf.predict_proba(x_va)[:,1]\n",
        "us_logloss = log_loss(y_va, y_va_pred)\n",
        "us_size = us_x_train.shape[0]\n",
        "y_te_pred = clf.predict_proba(x_te)[:,1]\n",
        "us_te_logloss = log_loss(y_te,y_te_pred)\n",
        "us_te_auc = roc_auc_score(y_te, y_te_pred)\n",
        "y_te_pred = clf.predict(x_te)\n",
        "us_te_acc = (y_te == y_te_pred).sum() / y_te.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTr5jkwnny2X"
      },
      "source": [
        "## **Result for comparision**\n",
        "## can be seen that our sigmoid UIDS log loss is much less as compared to random subsampling and full datset trained log loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dipLlzO7ntdY",
        "outputId": "139c49fc-6131-48c4-90c7-6894f04ee991"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Result Summary on Va\n",
            "[UIDS]  logloss 0.162497, # 4994\n",
            "[Random]   logloss 0.527064, # 4995\n",
            "[Full]     logloss 0.525831, # 8325\n",
            "Result Summary on Te\n",
            "[UIDS]  logloss 0.176543, # 4994\n",
            "[Random]   logloss 0.524031, # 4995\n",
            "[Full]     logloss 0.522210, # 8325\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"==\"*30)\n",
        "print(\"Result Summary on Va\")\n",
        "print(\"[UIDS]  logloss {:.6f}, # {}\".format(sb_logloss,sb_size))\n",
        "print(\"[Random]   logloss {:.6f}, # {}\".format(us_logloss,us_size))\n",
        "print(\"[Full]     logloss {:.6f}, # {}\".format(full_logloss,num_tr_sample))\n",
        "\n",
        "print(\"Result Summary on Te\")\n",
        "print(\"[UIDS]  logloss {:.6f}, # {}\".format(sb_te_logloss,sb_size))\n",
        "print(\"[Random]   logloss {:.6f}, # {}\".format(us_te_logloss,us_size))\n",
        "print(\"[Full]     logloss {:.6f}, # {}\".format(full_te_logloss,num_tr_sample))\n",
        "print(\"==\"*30)\n",
        "# Attention: if the dataset used here is small, one experiment may fail because of uncertainty of subsampling!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a6XxWsMo3xZ"
      },
      "source": [
        "## **Comparision of test accuracy on our UIDS technique , random subsamping and full dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwEqkYG01HAl",
        "outputId": "7fe0c145-150a-4392-c392-9f98efa914b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Result Summary on Te (ACC and AUC)\n",
            "[UIDS]  acc 0.984281, auc 0.998802 # 4994\n",
            "[Random]   acc 0.900139, auc 0.950359 # 4995\n",
            "[Full]     acc 0.916782, auc 0.961824 # 8325\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"==\"*30)\n",
        "print(\"Result Summary on Te (ACC and AUC)\")\n",
        "print(\"[UIDS]  acc {:.6f}, auc {:.6f} # {}\".format(sb_te_acc,sb_te_auc, sb_size))\n",
        "print(\"[Random]   acc {:.6f}, auc {:.6f} # {}\".format(us_te_acc,us_te_auc, us_size))\n",
        "print(\"[Full]     acc {:.6f}, auc {:.6f} # {}\".format(full_te_acc,full_te_auc, num_tr_sample))\n",
        "print(\"==\"*30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Trying Stuff with LIME**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8325, 784)\n",
            "(8325,)\n",
            "(3569, 784)\n",
            "(3569,)\n",
            "(2163, 784)\n",
            "(2163,)\n"
          ]
        }
      ],
      "source": [
        "#x_train,y_train,x_va,y_va,x_te,y_te\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_va.shape)\n",
        "print(y_va.shape)\n",
        "print(x_te.shape)\n",
        "print(y_te.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(38500, 28, 28, 3)\n",
            "(8325,)\n",
            "(31500, 28, 28, 3)\n",
            "(31500,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import gray2rgb, rgb2gray, label2rgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_vec = np.stack([gray2rgb(iimg) for iimg in mnist.data.values.reshape((-1, 28, 28))],0).astype(np.uint8)\n",
        "y_vec = mnist.target.astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Digit: 5')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "fig, ax1 = plt.subplots(1,1)\n",
        "ax1.imshow(X_vec[0], interpolation = 'none')\n",
        "ax1.set_title('Digit: {}'.format(y_vec[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "class PipeStep(object):\n",
        "    \"\"\"\n",
        "    Wrapper for turning functions into pipeline transforms (no-fitting)\n",
        "    \"\"\"\n",
        "    def __init__(self, step_func):\n",
        "        self._step_func=step_func\n",
        "    def fit(self,*args):\n",
        "        return self\n",
        "    def transform(self,X):\n",
        "        return self._step_func(X)\n",
        "\n",
        "\n",
        "makegray_step = PipeStep(lambda img_list: [rgb2gray(img) for img in img_list])\n",
        "flatten_step = PipeStep(lambda img_list: [img.ravel() for img in img_list])\n",
        "\n",
        "simple_rf_pipeline = Pipeline([\n",
        "    ('Make Gray', makegray_step),\n",
        "    ('Flatten Image', flatten_step),\n",
        "    #('Normalize', Normalizer()),\n",
        "    #('PCA', PCA(16)),\n",
        "    ('RF', RandomForestClassifier())\n",
        "                              ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vec, y_vec,\n",
        "                                                    train_size=0.55)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('Make Gray', <__main__.PipeStep object at 0x7f28a66f2940>),\n",
              "                ('Flatten Image', <__main__.PipeStep object at 0x7f28a66bfaf0>),\n",
              "                ('RF', RandomForestClassifier())])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "simple_rf_pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import os,sys\n",
        "try:\n",
        "    import lime\n",
        "except:\n",
        "    sys.path.append(os.path.join('..', '..')) # add the current directory\n",
        "    import lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lime import lime_image\n",
        "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
        "explainer = lime_image.LimeImageExplainer(verbose = False)\n",
        "segmenter = SegmentationAlgorithm('quickshift', kernel_size=1, max_dist=200, ratio=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95f035472c3147eaa2b944d09947932b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 30.4 s, sys: 2.54 s, total: 33 s\n",
            "Wall time: 28.9 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "explanation = explainer.explain_instance(X_test[0], \n",
        "                                         classifier_fn = simple_rf_pipeline.predict_proba, \n",
        "                                         top_labels=10, hide_color=0, num_samples=10000, segmentation_fn=segmenter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Positive/Negative Regions for 5')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "temp, mask = explanation.get_image_and_mask(y_test[0], positive_only=True, num_features=10, hide_rest=False, min_weight = 0.01)\n",
        "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (8, 4))\n",
        "ax1.imshow(label2rgb(mask,temp, bg_label = 0), interpolation = 'nearest')\n",
        "ax1.set_title('Positive Regions for {}'.format(y_test[0]))\n",
        "temp, mask = explanation.get_image_and_mask(y_test[0], positive_only=False, num_features=10, hide_rest=False, min_weight = 0.01)\n",
        "ax2.imshow(label2rgb(3-mask,temp, bg_label = 0), interpolation = 'nearest')\n",
        "ax2.set_title('Positive/Negative Regions for {}'.format(y_test[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x432 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, m_axs = plt.subplots(2,5, figsize = (12,6))\n",
        "for i, c_ax in enumerate(m_axs.flatten()):\n",
        "    temp, mask = explanation.get_image_and_mask(i, positive_only=True, num_features=1000, hide_rest=False, min_weight = 0.01 )\n",
        "    c_ax.imshow(label2rgb(mask,X_test[0], bg_label = 0), interpolation = 'nearest')\n",
        "    c_ax.set_title('Positive for {}\\nActual {}'.format(i, y_test[0]))\n",
        "    c_ax.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "  ## **Gaining Insight**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using #4285 where the label was 7 and the pipeline predicted 2\n"
          ]
        }
      ],
      "source": [
        "pipe_pred_test = simple_rf_pipeline.predict(X_test)\n",
        "wrong_idx = np.random.choice(np.where(pipe_pred_test!=y_test)[0])\n",
        "print('Using #{} where the label was {} and the pipeline predicted {}'.format(wrong_idx, y_test[wrong_idx], pipe_pred_test[wrong_idx]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8fc4e9a0926c4f0f91b091d73f25f888",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 25.7 s, sys: 1.3 s, total: 27 s\n",
            "Wall time: 24.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "explanation = explainer.explain_instance(X_test[wrong_idx], \n",
        "                                         classifier_fn = simple_rf_pipeline.predict_proba, \n",
        "                                         top_labels=10, hide_color=0, num_samples=10000, segmentation_fn=segmenter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqwAAAFSCAYAAAA3so3EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAoTElEQVR4nO3de5RcZZnv8d8DuTbpEIKRoQNpSAzXnAGMUYIiHoN4lgOapQ5iGME1cTEszHiBEVAxZAZlMccoZgZHl3qGiwTCzRkPDDdF0aB4SGIMMVwcyA0DCW2gk3QCuT7nj70jvd+qrtrV3VX1VtX3s1Yt8lTVvlTvH7ueevvtXebuAgAAAGJ1QL13AAAAACiFhhUAAABRo2EFAABA1GhYAQAAEDUaVgAAAESNhhUAAABRa+iG1cy+ZGY/KPH4+Wb2cBW2O9LM7jWzLWZ212CvH4OLnCAvsoI8yAnyIiuDyN1rdpO0VtJrknokbZJ0k6RRg7TuoyS5pCE1eB2fkPTEYG5L0gxJz0jaIennkjpreWxiupGTPtc3TNLd6c/HJb2n3seq3jey0uf6TpX0E0mvSOqSdJekw+t9vMhJdDk5QdJSSa+mt59KOqHex4usxJeVYN1z09dxZi2PTT1GWM9x91GS3irpbZKuqsM+DFSnpD+4+55KFzSzIUXue5OkH0n6iqSxSk4gdwx0JxscOSnuMUl/I2njQHasyZCVQodI+p6SN8hOSdsk3TiQHWwC5KTQi5I+quR9502S/q+kRQPaw+ZAVvp+bJKkv5b00gD2rX/q8MnlzF711yXdl/77g5JWSeqW9Kik43s97wpJG5ScdJ+VNCO9f56kW9N/r1fS8fekt+mSPinpsfTx70iaH+zPjyVdmv67Q9I9SkYj1kj6TB+v4R8l7ZK0O93ObCVTK66StE7Sy5JukXRw8IlqdrqPvyyyzosk/bpXfZCST3jH1fL4xHIjJ8VzEqz/j2KElazkyEq6zFslbav38SIn8eZE0hBJn5a0o97Hi6zEmxVJD0r6QPhzqsmxqVcQJB2ZHvhrJB0jabuk90kaKulySc8p+RXosZJekNTR6wc7qUgQ9v/Ah/TaXu8gvDtdj6X1IUqawo70QC5TMsw9TNJESaslvb+P1/Hn7ab136b7O1HSKCWjpT8M9usWJY3oyCLrWyDpO8F9v5f0kVoen1hu5KR4ToJ107CSlVxZSZf5nKTf1Pt4kZM4c6KkAdsjaZ+kq+p9vMhKnFlRMrL64/DnVKtbPaYE/KeZdSv51eYvJF0r6WOS/svdf+LuuyXNlzRS0mmS9koaLukEMxvq7mvd/fl+bHexkgNyelp/VNLj7v6ipGmSxrn7P7n7LndfLen7ks7Lue7zJX3T3Ve7e4+kL0o6LxhWn+fu2939tSLLj5K0Jbhvi6T2nNtvRuQEeZGVEszsL5W8yX0h9ytrTuSkD+4+RtLBkuZIWl7Ba2tWZCVgZu1Kfg6f7cfrGhR9zlOoopnu/tPed5hZh5JhakmSu+8zsxckjXf3R83sc0o+LZxoZg8pGR5/sZKNurub2SJJH5f0S0mzJN2aPtwpqSMN6H4HKglPHpn9T/89RNJhve57ocTyPZJGB/eNVvKrhVZFTpAXWemDmb1F0gOSPuvuebfdrMhJ6f3cbmbfldRlZse7+8s596EZkZVC85SMyK7Nub1BF8tlrV5UcjAkSWZmSobiN0iSu9/m7u9Kn+OS/rnIOjzHdm6X9FEz65T0DiVzQaTkIK1x9zG9bu3u/oH+7L+kCUp+vbIp5/6tknTS/sLMDpI0Kb0fb2j1nCC/ls9Kuk8/lXSNu/8w53ZbTcvnJHCApDZJ4ytYplW0elZmSPqMmW00s41KXvudZnZFzu0PWCwN652S/srMZpjZUEmXSdop6ddmdqyZvdfMhkt6Xcl8jn1F1tGV3j+xr424+3JJf5L0A0kPuXt3+tATkraZ2RXptcsONLMpZjYt5/7fLunzZna0mY1SMmx+h+f/67z/kDTFzD5iZiOU/PruSXd/JufyraLVcyIzG55mRJKGmdmI9MSJrJbOipmNl/QzSTe4+3dzbrMVtXpO3mdmp6TbHS3pm0oub/V0zu23kpbOipKGdYqkk9Pbi5L+TtK3cy4/YFE0rO7+rJJL9fyrkgN1jpLLSuxSMi/kuvT+jZLerGTuRbiOHZK+JulXZtZtZqf2sbnbJJ2Z/nf/snslna3kIKzRG2E5OOdL+HdJP1QyhL9GSWD/PueycvcuSR9J9/9VJZ+q8s5LaRmtnpPUs0pOhuMlPZT+u7PkEi2IrOhTSt4U55lZz/5bBcu3BHKiMUoamS2Snlfym73/5e6vV7COltDqWXH3ze6+cf9NybzdV9P5sDWx/y/RAAAAgChFMcIKAAAA9IWGFQAAAFGjYQUAAEDUaFgBAAAQNRrWCpjZPDO7tfwz0erICvIgJ8iLrCCPZs5JQzWsZvaomb2aXussz/M/aWaPVXu/0m2d3/vyMWa2w8zczKbWYvvIIivIg5wgL7KCPMhJ9TRMw2pmRyn5fl2X9MH67k0hd1/o7qP23yRdImm1pN/WeddaDllBHuQEeZEV5EFOqqthGlZJF0j6jaSbJF3Y+wEzO9LMfmRmXWa22cxuMLPjJX1X0vT0k0R3+txHzexTvZbNfLoxswVm9oKZbTWzZWZ2ej/390JJtzgXuq0HsoI8yAnyIivIg5xUUaM1rAvT2/vN7DBJMrMDJd0naZ2ko5R8A9Aid39a0sWSHk8/TYzJuZ0lSr5JYqySb5m4y974KsxcLPkO4HdLuqWS5TBoyAryICfIi6wgD3JSRQ3RsJrZu5R8/eSd7r5MyVfIzUoffrukDklfcPft7v66u/d7Poi735p+Bdked/+Gkq9cO7bC1VwgabG7r+nvfqB/yAryICfIi6wgD3JSfQ3RsCoZtn7Y3f+U1rfpjeH2IyWtc/c9g7EhM/sHM3vazLakw/MHS3pThau5QNLNg7E/qBhZQR7kBHmRFeRBTqpsSL13oBwzGynpXEkHmtnG9O7hksaY2UmSXpA0wcyGFAlDsXkZ2yW19ar/ote2Tpd0uaQZkla5+z4ze1WSVbC/71TySeruvMtgcJAV5EFOkBdZQR7kpDYaYYR1pqS9kk5QMmfjZEnHS1qs5BPCE5JeknSdmR1kZiPSgyFJmyQdYWbDeq3vd5I+bGZtZvYWSbN7PdYuaY+kLklDzGyupNEV7u+Fku5x920VLoeBmymygvJmipwgn5kiKyhvpshJ1TVCw3qhpBvdfb27b9x/k3SDpPOVfKo4R9JbJK2X9EdJH0uX/ZmkVZI2mtn+YfrrJe1SEpKblUyO3u8hSQ9K+oOSydGvK/lklEs66flcNdgwexMhK8iDnCAvsoI8yEkNWINczQAAAAAtqhFGWAEAANDCaFgBAAAQNRpWAAAARI2GFQAAAFEreR1WM4vuL7LOrvcONLB73XNfp61SMWYF/edVykqMOeGc0n+cU2qvUfNarayQk+ZS6r2HEVYAAABEjYYVAAAAUaNhBQAAQNRKzmGNQaPO1wEQJ84pANB4GGEFAABA1GhYAQAAEDUaVgAAAEQt+jmsAAA0C+ZQA/3DCCsAAACiRsMKAACAqNGwAgAAIGo0rAAAAIgaDSsAAACiRsMKAACAqNGwAgAAIGo0rAAAAIgaDSsAAACiRsMKAACAqNGwAgAAIGo0rAAAAIjakFpvcNasWZl6+vTpmXrFihWZuru7O1OPWbw4U7/c1VWwjZEjRmTqYcOHZ+rhw4Zl6o2bNmWfHzxebn2S1FVkPzAwA83K4iArxY7RiODYDg+ObZiFTWWyUm59fe0H+o9zCvKK4ZyyJMjCNLISnduCnJxWJievBjm5gveeqmCEFQAAAFGjYQUAAEDUaFgBAAAQtZrPYT366KMz9YQJE0rWBT7xiUw5fvnygqccOnZspj7kkEMydfvo0Zl66ZIl2cfb2zP12EMPzdQHB8tL0v3335+pb7zppoLnoDIDzcongqwsL5KVsWWyMjo41kvKZOXQICvh8lJhVm4iKwPCOQV5DfY5haw0p4lBTo4MchHWoTAn1/DeMygYYQUAAEDUaFgBAAAQNRpWAAAARK3qc1hHjhyZqceNGzeo699wyikF9xXeU9q0adMytZd5/u5duwrue3Llygq3Wpn7itx3dlW3WHvVzsopRbJSqTAr5ewqkpWVVc5Ks+OcMjg4pwwcWWkO1c7JV4rkpNjPtBTeexhhBQAAQORoWAEAABA1GlYAAABErepzWMNrgYXXwQvt27cvUx8ZfGfvqmD58Ptz0zsz5faenkzd1taWqe2AbN++Y/v2ko/v3r27YJMrn3yycD+qLJwD0+hzigaalfD7ncPli2UlvK+nTFYOCLKwPchK+HixrDxZh6w0E84p1cM5hazk1UxZCXNyVJmceJCTrwY5+Uyw/PAcOeG9pzxGWAEAABA1GlYAAABEjYYVAAAAUav6HNZKbd26NVO/bd68ks8v9t3P6zo7M/W1wbXHLp08OVOH85CuW7UqU8+bOjVTd86ZU7DNSy65JFN/a8GCPvY4n0qv0VZsmUaeU5RHmJV5/chKZ5CV8Dp1k8tkZVWQlalBVubkyMqCAWYFpXFOSXBOKY+sJMhKaWFOlgY5uSB4frGcrAxy0hnk5NkyOZkY5OTFICcPFsnJ0gZ/72GEFQAAAFGjYQUAAEDUaFgBAAAQtejmsFZq/fr1BfddXuS+3uYuWTLo+3Hcccdl6vb29ky9bdu2Qd8mKlMsK8Xu620JWWk5nFOQF1lBHsVycnBwX3fw+GFlcrK5H/vR6DlhhBUAAABRo2EFAABA1GhYAQAAEDUaVgAAAEQtuj+6euCBB+q9C/2yrKMjUx9++OGZuh6Tmftz8edG0qhZ6YgwK82sUXPCOaX2yMrgaeas3N+gObkoyMn1EeSkEoywAgAAIGo0rAAAAIgaDSsAAACiVvU5rFu3bs3UixYtytThfL4777yz2ruESJEV5EFOkBdZQR5hTu4ok5O7yEldMMIKAACAqNGwAgAAIGo0rAAAAIha1eewvvbaa5n69ttvr/YmB928Zcsy9fd27y54ztChQ2u1O02rGbKyLMjKbrIy6JohJ5xTaoOsII8wJ7OCnJxdy53pp8Nb4L2HEVYAAABEjYYVAAAAUaNhBQAAQNSqPoe1GbzyyiuZet++fXXaE8SOrCAPcoK8yEr93RfUMc5pbYWcMMIKAACAqNGwAgAAIGo0rAAAAIhaS85hbWtry9Tt7e2Zuru7O1Pv3LkzU4fXbJOk4cOHD87OISpkBXmQE+RFVpDHQRXm5PUcORnR4DlhhBUAAABRo2EFAABA1GhYAQAAELXo57COGzcuU48ZMyZTr1mzpmCZPXv2ZOrTTjstU5933nmZurOzM1MvXLgwU09+5plMvWLFioJtnnHGGZl611lnZeqTRowoWKaUh4Nt7tq1q6LlW1EMWXmmH1k5K8jKiAqzEm6TrJRWjZwsLJOTW4OcPBscswlFcvLuICfDg5yM5JxSdTGcU/K8/3w9yMpPeP+pqcHIyTuDnBxUYU7WB8fsa0343sMIKwAAAKJGwwoAAICo0bACAAAgaubufT9o1veDVTJs2LBMffXVV2fqyZMnZ+qurq6CdTz33HOZ+tRTT83Ulc7TqIeLLrooU2/atGnA63R3G/BK+kBW6qeRshJDTpb2Iyf/XWFOwh9ezV90EWFO/k/EOZHiyEqM55RafI99B+eUkj4c5GRqhDmphVq/9zDCCgAAgKjRsAIAACBqNKwAAACIGg0rAAAAohbdFwe0tbVl6ilTppR8/hFHHJHrvlLMsnN8S/0hGuJBVpBHmJMTy+RkfJFMFLuvFHLSmDinIA9yUh+MsAIAACBqNKwAAACIGg0rAAAAohbdHNbt27dn6scffzxTT58+fdC3Gc4F2bFjR6bu6enJ1Nu2bStYx6RJkyraZniB3e7u7ky9e/fuitbXishKgqyU1qo52VImJ7W4AH2jaYSsLCiSlc9WOSvIuiPIyRER5qQZ33sYYQUAAEDUaFgBAAAQNRpWAAAARC26OazhnIibb745U5944omZutg8jdD48eNLPr5z585MPX/+/Ez9/PPPl93m3LlzM/XJJ5+cqR955JFMHb6uLVu2lNxHFCIryCPMyS3Bz3NKP3LSUSYnrwc5+UaQk2/lyMmSICcnBTn5WZCTm8jJgIVZeSX4mW6twTnl2X5kZVuQlauCrHyec8qg4r2nPhhhBQAAQNRoWAEAABA1GlYAAABELbo5rKGXXnopU1988cWZeu/evQXLTJw4MVNv2LCh5OOzZ8/O1MuWLat4P+++++5MHc4N2bx5c6au91yQZkRWkMf3gpxsDXKyp0hOJgU5+GOFOZnXj5zcFeQknMNKTqpvMLLyqzJZOWwQshKeU8I5rGSlunjvqQ1GWAEAABA1GlYAAABEjYYVAAAAUYt+Dmso/K7nYp566qmSjy9fvjxTz5kzZ0D7JBVe8yy8Ztro0aMHvA1UhqzEL4bvs+/JkZNVFebkqCrkZFcL50Rq3qzcR1aaDu891cEIKwAAAKJGwwoAAICo0bACAAAgag03hzVWa9euzdTr1q3L1DNmzMjU4fXQurq6qrJfiA9ZQR43BDn5dJCT95bJycvkpGWE55QbgqxczzkFavz3HkZYAQAAEDUaVgAAAESNhhUAAABRYw5rlaxevTpTH3PMMZn6sssuy9RXXnll1fcJcSIryGNNmZxcSk6QCs8pQzmnoIhGe+9hhBUAAABRo2EFAABA1GhYAQAAEDUaVgAAAETN3L3vB836fhANx92tWusmK82lWlkJc3J2NTYSgfvqsM16/CzvreE5haw0tlqdU9DYSuWEEVYAAABEjYYVAAAAUaNhBQAAQNRoWAEAABA1GlYAAABEjYYVAAAAUaNhBQAAQNRoWAEAABA1GlYAAABEjYYVAAAAUaNhBQAAQNTMna/hBQAAQLwYYQUAAEDUaFgBAAAQNRpWAAAARI2GFQAAAFGjYQUAAEDUaFgBAAAQNRpWAAAARI2GFQAAAFGjYQUAAEDUaFgBAAAQNRpWAAAARI2GFQAAAFGjYQUAAEDUaFgBAAAQNRpWAAAARI2GFQAAAFGjYQUAAEDUaFgBAAAQNRpWAAAARI2GFQAAAFGjYQUAAEDUaFgBAAAQNRpWAAAARI2GFQAAAFGjYQUAAEDUaFgBAAAQNRpWAAAARI2GFQAAAFGjYQUAAEDUaFgBAAAQNRpWAAAARK2hG1Yz+5KZ/aDE4+eb2cNV2O5IM7vXzLaY2V2DvX4MLnKCvMgK8iAnyIusDCJ3r9lN0lpJr0nqkbRJ0k2SRg3Suo+S5JKG1OB1fELSE4O1rV773tPr9pVaHpuYbuSk5DrbJP2bpD9J2iLpl/U+XmQlvqxIOj84n+xIX8vUeh8zchJPTtJ1nivpaUnbJD0laWa9jxdZiTYrn5L0XPqzeVBSRy2PTT1GWM9x91GS3irpbZKuqsM+DFSnpD+4+55KFzSzISUeHuPuo9LbNf3fvaZATor7nqSxko5P//v5/u9e0yArAXdf2OtcMkrSJZJWS/rtwHe1YZGTwvvGS7pV0qWSRkv6gqTbzOzNA93RBkdWCu97j6RrJX1IyXvPGkm3D2wXK1TL7ljJJ5cze9Vfl3Rf+u8PSlolqVvSo5KO7/W8KyRtUPIJ8FlJM9L750m6Nf33emVHKadL+qSkx9LHvyNpfrA/P5Z0afrvDkn3SOpSciA+08dr+EdJuyTtTrczW8nUiqskrZP0sqRbJB3s2U9Us9N9LBgRUw0/dTXCjZz0mZPjJG2VNLrexyiWG1kpnpUi2/i5pKvrfbzISVw5kfQOSS8H93VJml7vY0ZWosvKfEnf7lV3pMtMqtmxqVcQJB2ZHvhrJB0jabuk90kaKulyJcPOwyQdK+kFpUPP6Q92UpEg7P+BD+m1vd5BeHe6HkvrQ5QM+3ekB3KZpLnpNicqGY14fx+v48/bTeu/Tfd3oqRRkn4k6YfBft0i6SBJI4usb/9zNkj6o6QbJb2pXv/D1vtGTvrMyQWSVkq6XsmUgJWSPlLv40VW4stKsO5OSXslHV3v40VO4sqJpAMl/UJJI3agpJlK3oMOqvcxIyvRZWW+pH/rVY9Pl/lQrY5NPaYE/KeZdUt6TMn/KNdK+pik/3L3n7j77vQHM1LSaUpOtMMlnWBmQ919rbs/34/tLlbywz09rT8q6XF3f1HSNEnj3P2f3H2Xu6+W9H1J5+Vc9/mSvunuq929R9IXJZ0XDKvPc/ft7v5akeX/lO5Dp6SpktolLazw9TUbclLoCElTlMxd7ZA0R9LNZnZ8ha+x2ZCV0i6QtNjd1+TcdrMiJwF336ukSblN0s70v3/n7tsrf5lNhawUelDSuWb2l2Y2Uknj7Er+rqIm6tGwznT3Me7e6e6XpD+YDiXD1JIkd9+n5FPGeHd/TtLnlHxaeNnMFplZR6Ub9eQjwSJJH0/vmqU3msJOSR1m1r3/JulLkg7LufrM/qf/HhIs/0KJfetx96XuvsfdNylpRM4ys/ac229G5KTQa0p+xfPV9IT1CyW/6j0r5/abFVkp7QJJN+d8bjMjJwEzO1PS/5b0HiWjdmdI+oGZnZxz+82KrBTu208lXa1kSsLa9LZNyYh8TcRyWasXlRwMSZKZmZKh+A2S5O63ufu70ue4pH8usg7PsZ3bJX3UzDqVzN25J73/BUlr0oDuv7W7+wf6s/+SJkjao+QvDCvZv/C5sRyfWLR6Tp4scl8luWolrZ4VSZKZvVPJG9XdObfbalo9Jycrma+41N33ufsSSf9P0pk5t99KWj0rcvdvu/tkdz8s3a8hkn6fc/sDFktDdKekvzKzGWY2VNJlSn498WszO9bM3mtmwyW9rmSUaV+RdXSl90/sayPuvlzJr99/IOkhd+9OH3pC0jYzuyK9dtmBZjbFzKbl3P/bJX3ezI42s1FKfn1wh+f86zwze0f6Og8ws0Ml/YukR919S87tt4qWzomkXyqZEP9FMxuSNiP/U9JDOZdvJa2elf0ulHSPu2+rcLlW0eo5WSLp9P0jqmZ2ipJfRxf7cNzqWjorZjYi3Z6Z2QQlV6xZ4O6v5tz+gEXRsLr7s5L+RtK/KjlQ5yi5rMQuJfNCrkvv3yjpzUrmXoTr2CHpa5J+lQ6Xn9rH5m5T8unxtl7L7pV0tpJPm2v0RlgOzvkS/l3SD5U0FGuUBPbvcy4rJeF9UMnw+u+V/E/w8ZJLtKBWz4kn86Y+JOkDSuaxfl/SBe7+TN51tIpWz4qUvMEoucYm0wH60Oo5SacVzZN0t5ltUzJqdq27D/qF7Btdq2dF0oh0f3qUNM+PS/pKBcsP2P6/RAMAAACiFMUIKwAAANAXGlYAAABEjYYVAAAAUaNhBQAAQNRoWCtgZvPM7NZ67wfiR1aQBzlBXmQFeTRzThqqYTWzR83s1fRaZ3me/0kze6za+5Vu63wz6+l122FmbmZTa7F9ZJEV5EFOkBdZQR7kpHoapmE1s6OUXNDYJX2wvntTyN0Xuvuo/TdJl0haLem3dd61lkNWkAc5QV5kBXmQk+pqmIZVyfdh/0bSTUq+veXPzOxIM/uRmXWZ2WYzu8HMjpf0XUnT008S3elzHzWzT/VaNvPpxswWmNkLZrbVzJaZ2en93N8LJd3iXOi2HsgK8iAnyIusIA9yUkWN1rAuTG/vN7PDJMnMDpR0n6R1ko6SNF7SInd/WtLFkh5PP02MybmdJUq+SWKskm91uMuSb4zJzZLvAH63pFsqWQ6DhqwgD3KCvMgK8iAnVdQQDauZvUtSp6Q73X2ZpOclzUoffrukDklfcPft7v66u/d7Poi73+rum919j7t/Q8lXrh1b4WoukLTY3df0dz/QP2QFeZAT5EVWkAc5qb6GaFiVDFs/7O5/Suvb9MZw+5GS1rn7nsHYkJn9g5k9bWZb0uH5gyW9qcLVXCC+v7teyAryICfIi6wgD3JSZUPqvQPlmNlISedKOtDMNqZ3D5c0xsxOkvSCpAlmNqRIGIrNy9guqa1X/Re9tnW6pMslzZC0yt33mdmrkqyC/X2nkk9Sd+ddBoODrCAPcoK8yAryICe10QgjrDMl7ZV0gpI5GydLOl7SYiWfEJ6Q9JKk68zsIDMbkR4MSdok6QgzG9Zrfb+T9GEzazOzt0ia3euxdkl7JHVJGmJmcyWNrnB/L5R0j7tvq3A5DNxMkRWUN1PkBPnMFFlBeTNFTqquERrWCyXd6O7r3X3j/pukGySdr+RTxTmS3iJpvaQ/SvpYuuzPJK2StNHM9g/TXy9pl5KQ3KxkcvR+D0l6UNIflEyOfl3JJ6Nc0knP56rBhtmbCFlBHuQEeZEV5EFOasAa5GoGAAAAaFGNMMIKAACAFkbDCgAAgKjRsAIAACBqNKwAAACIWsnrsJoZf5HVRNw993XaKkVWmku1skJOmgvnlNo7u9470E/3ck6pqWbMCSOsAAAAiBoNKwAAAKJGwwoAAICo0bACAAAgajSsAAAAiBoNKwAAAKJGwwoAAIColbwOKwAAGDyNen1M1BY5KcQIKwAAAKJGwwoAAICo0bACAAAgajSsAAAAiBoNKwAAAKJGwwoAAICo0bACAAAgajSsAAAAiBoNKwAAAKJGwwoAAICo0bACAAAgajSsAAAAiNqQWm9w1qxZmXr69OmZesWKFZm6u7s7Uy9evDhTd3V1FWxjxIgRmXr48OGZetiwYZl606ZNJR8vt76+9gMDQ1aQx21BTk4rk5NXg5xcQU5aRgznlCVBFqaVycrIYH3DyErVxXBOISeFGGEFAABA1GhYAQAAEDUaVgAAAETN3L3vB836frCfvvzlL2fqt7/97QNa3/LlywvuGzt2bKY+5JBDMvXo0aMz9ZIlSzJ1e3t7pj700ENLLi9J999/f6a+6aabiu9wHbm7VWvdZCVBVkqrRk5+E+Rk2gBzcg05ya3Vzynji2Tl0DJZaQ+O9dIyWRkbZOXgHFm5McKs3NvC55Ri7z3kpLhSOWGEFQAAAFGjYQUAAEDUaFgBAAAQtapfh3XkyJGZety4cYO6/lNOOWXA65g2bVpFz9+1a1fBfStXrhzwfrQ6soI8qp2TrxTJyX0VroOcxKHaWdlQJCuVnmXCrJSbkLm7SFaerHJWiuX/7KpusbYa8b2nFXPCCCsAAACiRsMKAACAqNGwAgAAIGpVn8MaXl/w6KOPLvn8ffv2ZerwO3vD5cPv4y12X09PT6Zua2vL1AcckO3bt2/fXvLx3bt3F2zzySefLLgPlSEryCPMyVFlcuJBTr4a5OQzwfLDi+RE5KQhDfSccmSQlVU5zilhVraXyYoFWdgRZCV8vFhWVtYhK+F8xUae0zrQc8rvgpxMzHFOCbNDTspjhBUAAABRo2EFAABA1GhYAQAAELWqz2Gt1NatWzP1vHnzSj5/woQJBfd1dnZm6vB6hpMnT87U4VySVatWZeqpU6dm6jlz5hRs85JLLsnUCxYs6GOPMVjICvIIc7I0yMkFwfOL5WRlkJPOICfPlsnJxCAnLwY5ebBITpaSk5oLs/K2fpxT1gVZuTbIyqVlsnJdkJV5QVY6c5xTvjXArFR63eFiyzTynNZyBuO956ggJ+E1Uo8Z4HvPp5swJ4ywAgAAIGo0rAAAAIgaDSsAAACiFt0c1kqtX78+1329LVmyZND347jjjsvU7e3tmXrbtm2Dvk1Uhqwgj2KZODi4rzt4/LAyOdncj/0gJ/ErlpXLy5xT5nJOaTn9ee95gpwUYIQVAAAAUaNhBQAAQNRoWAEAABA1GlYAAABELbo/unrggQfqvQv90tHRkakPP/zwTB37ZOZGRFaQx/0NmpOLgpxcT06qrlHPKcsiPKf056LyjaJRzymHN3hOGGEFAABA1GhYAQAAEDUaVgAAAESt6nNYt27dmqkXLVqUqcP5fHfeeWe1dwmRIivII8zJHWVychc5aVmcU5AH55TGwAgrAAAAokbDCgAAgKjRsAIAACBqVZ/D+tprr2Xq22+/vdqbHHTLli3L1Lt37y54ztChQ2u1O02LrCCPMCezgpycXcud6afDyUlNNMM5ZV6Qle+RlUHXDOeUpS1wTmGEFQAAAFGjYQUAAEDUaFgBAAAQtarPYW0Gr7zySqbet29fnfYEsSMr9Rd+N3WM88/ICfIiK/XHOSUOjLACAAAgajSsAAAAiBoNKwAAAKLWknNY29raMnV7e3um7u7uztQ7d+7M1OE12yRp+PDhg7NziApZQR4HVZiT13PkZAQ5aUqcU5AH55RCjLACAAAgajSsAAAAiBoNKwAAAKIW/RzWcePGZeoxY8Zk6jVr1hQss2fPnkx92mmnZerzzjsvU3d2dmbqhQsXZupnnnkmU69YsaJgm2eccUamPuusszL1iBEjCpYpJdzmrl27Klq+FVUjKwvLZOXWICvzg+M2oUhWtgZZ+ZcgK5eTlaoajJy8M8jJQRWeU9YHx+xrnFOiFMP7z+R+vP/sCrJyUoVZeZisVCSGc8pJOc4pX2/wnDDCCgAAgKjRsAIAACBqNKwAAACImrl73w+a9f1glQwbNixTX3311Zl68uTJmbqrq6tgHc8991ymPvXUUzN1pXO/6uGiiy7K1Js2bRrwOt3dBrySPsSQlaX9yMp/V5iV8AdY7kWH30FdDY2UlXrk5MNBTqZyTpEUd06kOM4pvP8kYs4K55Tizh7Q0vl01DgnjLACAAAgajSsAAAAiBoNKwAAAKJGwwoAAICoRffFAW1tbZl6ypQpJZ9/xBFH5LqvFLPsHN9Sf4iGeIRZObFMVsYXyUWx+0ohK42HcwryIivIg5zUByOsAAAAiBoNKwAAAKJGwwoAAICoRTeHdfv27Zn68ccfz9TTp08f9G2Gc0F27NiRqXt6ejL1tm3bCtYxadKkirYZXmC3u7s7U+/evbui9bWiRsjK8UWy8jRZqak7gpwcEWFOOKfEoRHOKWSl/hrhnLKgSE4+O8CcbKlzThhhBQAAQNRoWAEAABA1GlYAAABELbo5rOGciJtvvjlTn3jiiZm62Hye0Pjx40s+vnPnzkw9f/78TP3888+X3ebcuXMz9cknn5ypH3nkkUwdvq4tW7aU3EcUCrPy18HP9Ol+ZKWjTFZeD7Lynn5kZUmQlReCrLQFWfkCWRkQzinIi6wgj0bNybYgJ1cFOfl85DlhhBUAAABRo2EFAABA1GhYAQAAELXo5rCGXnrppUx98cUXZ+q9e/cWLDNx4sRMvWHDhpKPz549O1MvW7as4v28++67M3U4h2jz5s2Zut5zQZpRmJXxVcjKfwxCVi4MsvJVslJTnFOQF1lBHo2ak3AOa+w5YYQVAAAAUaNhBQAAQNRoWAEAABC16OewhsLvei7mqaeeKvn48uXLM/WcOXMGtE9S4TXPwmumjR49esDbQGWqkZWjyErT4ZyCvMgK8miUnOxqsJwwwgoAAICo0bACAAAgajSsAAAAiFrDzWGN1dq1azP1unXrMvWMGTMydXg9tK6urqrsF+ITZuV/BFlZFWRlHFlpSZxTkBdZQR5hTm4IcnJ95DlhhBUAAABRo2EFAABA1GhYAQAAEDXmsFbJ6tWrM/UxxxyTqS+77LJMfeWVV1Z9nxCnNUFWhgZZ+XmQlSlkpSVxTkFeZAV5hDkJ33tiywkjrAAAAIgaDSsAAACiRsMKAACAqNGwAgAAIGrm7n0/aNb3g2g47m7VWjdZaS7Vygo5aS6cU5AX5xTkUSonjLACAAAgajSsAAAAiBoNKwAAAKJGwwoAAICo0bACAAAgajSsAAAAiBoNKwAAAKJGwwoAAICo0bACAAAgajSsAAAAiBoNKwAAAKJm7nwNLwAAAOLFCCsAAACiRsMKAACAqNGwAgAAIGo0rAAAAIgaDSsAAACiRsMKAACAqP1/iceQgAK1qRcAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 864x432 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, m_axs = plt.subplots(2,5, figsize = (12,6))\n",
        "for i, c_ax in enumerate(m_axs.flatten()):\n",
        "    temp, mask = explanation.get_image_and_mask(i, positive_only=True, num_features=10, hide_rest=False, min_weight = 0.01 )\n",
        "    c_ax.imshow(label2rgb(mask,temp, bg_label = 0), interpolation = 'nearest')\n",
        "    c_ax.set_title('Positive for {}\\nActual {}'.format(i, y_test[wrong_idx]))\n",
        "    c_ax.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Subsampling for LIME**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Unweighted Data Subsampling via Influence Function.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "86519fbbec93c191aacc49d4c33e96a49fd6ef772decd8151fefe193caa932bd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
