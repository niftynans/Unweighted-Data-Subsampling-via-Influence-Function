{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import gray2rgb, rgb2gray, label2rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import sys\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from inverse_hvp import inverse_hvp_lr_newtonCG\n",
    "import argparse\n",
    "import time\n",
    "import pdb\n",
    "import os\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the dataset used\n",
    "dataset_name = \"mnist\"\n",
    "# regularization parameter for Logistic Regression\n",
    "C = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train-images-idx3-ubyte.gz\n",
      "Extracting train-labels-idx1-ubyte.gz\n",
      "Extracting t10k-images-idx3-ubyte.gz\n",
      "Extracting t10k-labels-idx1-ubyte.gz\n",
      "x_train, nr sample 9104, nr feature 28\n",
      "x_va,    nr sample 3903, nr feature 28\n",
      "x_te,    nr sample 2163, nr feature 28\n",
      "Tr: Pos 4784 Neg 4320\n",
      "Va: Pos 1958 Neg 1945\n",
      "Te: Pos 1135 Neg 1028\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# tool box\n",
    "def load_mnist(validation_size = 5000):\n",
    "    import gzip\n",
    "    def _read32(bytestream):\n",
    "        dt = np.dtype(np.uint32).newbyteorder(\">\")\n",
    "        return np.frombuffer(bytestream.read(4),dtype=dt)[0]\n",
    "\n",
    "    def extract_images(f):\n",
    "        print(\"Extracting\",f.name)\n",
    "        with gzip.GzipFile(fileobj=f) as bytestream:\n",
    "            magic = _read32(bytestream)\n",
    "            num_images = _read32(bytestream)\n",
    "            rows = _read32(bytestream)\n",
    "            cols = _read32(bytestream)\n",
    "            buf = bytestream.read(rows * cols * num_images)\n",
    "            data = np.frombuffer(buf,dtype=np.uint8)\n",
    "            data = data.reshape(num_images,rows,cols,1)\n",
    "            return data\n",
    "    \n",
    "    def extract_labels(f):\n",
    "        print('Extracting', f.name)\n",
    "        with gzip.GzipFile(fileobj=f) as bytestream:\n",
    "            magic = _read32(bytestream)\n",
    "            num_items = _read32(bytestream)\n",
    "            buf = bytestream.read(num_items)\n",
    "            labels = np.frombuffer(buf, dtype=np.uint8)\n",
    "            return labels\n",
    "\n",
    "    #data_dir = \"./data\"\n",
    "    data_dir = \"\"\n",
    "    TRAIN_IMAGES = os.path.join(data_dir,'train-images-idx3-ubyte.gz')\n",
    "    with open(TRAIN_IMAGES,\"rb\") as f:\n",
    "        train_images = extract_images(f)\n",
    "\n",
    "    TRAIN_LABELS =  os.path.join(data_dir,'train-labels-idx1-ubyte.gz')\n",
    "    with open(TRAIN_LABELS,\"rb\") as f:\n",
    "        train_labels = extract_labels(f)\n",
    "\n",
    "    TEST_IMAGES =  os.path.join(data_dir,'t10k-images-idx3-ubyte.gz')\n",
    "    with open(TEST_IMAGES,\"rb\") as f:\n",
    "        test_images = extract_images(f)\n",
    "\n",
    "    TEST_LABELS =  os.path.join(data_dir,'t10k-labels-idx1-ubyte.gz')\n",
    "    with open(TEST_LABELS,\"rb\") as f:\n",
    "        test_labels = extract_labels(f)\n",
    "\n",
    "    # split train and val\n",
    "    # train_images = train_images[validation_size:]\n",
    "    # train_labels = train_labels[validation_size:]\n",
    "\n",
    "    # preprocessing\n",
    "    # train_images = train_images.astype(np.float32) / 255\n",
    "    # test_images  = test_images.astype(np.float32) / 255\n",
    "    \n",
    "    # reshape for logistic regression\n",
    "    # train_images = np.reshape(train_images, [train_images.shape[0], -1])\n",
    "    # test_images = np.reshape(test_images, [test_images.shape[0], -1])\n",
    "    return train_images,train_labels,test_images,test_labels\n",
    "\n",
    "def load_data_two_class(dataset_name,va_ratio):\n",
    "  x_train,y_train,x_test,y_test = load_mnist()\n",
    "  pos_class = 1\n",
    "  neg_class = 7\n",
    "  x_train,y_train = filter_dataset(x_train,y_train,pos_class,neg_class)\n",
    "  x_va,y_va = filter_dataset(x_test,y_test,pos_class,neg_class)\n",
    "  y_va = y_va.astype(int)\n",
    "  y_train = y_train.astype(int)\n",
    "\n",
    "  num_va_sample = int((1-va_ratio) * x_train.shape[0])\n",
    "  x_val = x_train[num_va_sample:]\n",
    "  y_val = y_train[num_va_sample:]\n",
    "  x_train = x_train[:num_va_sample]\n",
    "  y_train = y_train[:num_va_sample]\n",
    "  x_te = x_va\n",
    "  y_te = y_va\n",
    "\n",
    "  return x_train,y_train,x_val,y_val,x_te,y_te\n",
    "\n",
    "\n",
    "def filter_dataset(X, Y, pos_class, neg_class, mode=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Filters out elements of X and Y that aren't one of pos_class or neg_class\n",
    "    then transforms labels of Y so that +1 = pos_class, -1 = neg_class.\n",
    "\n",
    "    They are all 10-classes image classification data sets while Logistic regression can only handle binary classification. we\n",
    "    select the number 1 and 7 as positive and negative classes;\n",
    "    \"\"\"\n",
    "\n",
    "    assert(X.shape[0] == Y.shape[0])\n",
    "    assert(len(Y.shape) == 1)\n",
    "\n",
    "    Y = Y.astype(int)\n",
    "    \n",
    "    pos_idx = Y == pos_class\n",
    "    neg_idx = Y == neg_class        \n",
    "    Y[pos_idx] = 1\n",
    "    Y[neg_idx] = -1\n",
    "    idx_to_keep = pos_idx | neg_idx\n",
    "    X = X[idx_to_keep, ...]\n",
    "    Y = Y[idx_to_keep]\n",
    "    if Y.min() == -1 and mode != \"svm\":\n",
    "        Y = (Y + 1) / 2\n",
    "        Y.astype(int)\n",
    "    return (X, Y)\n",
    "\n",
    "# load data, pick 30% as the Va set\n",
    "x_train,y_train,x_va,y_va,x_te,y_te = load_data_two_class(dataset_name,va_ratio=0.3)\n",
    "\n",
    "\n",
    "\n",
    "print(\"x_train, nr sample {}, nr feature {}\".format(x_train.shape[0],x_train.shape[1]))\n",
    "print(\"x_va,    nr sample {}, nr feature {}\".format(x_va.shape[0],x_va.shape[1]))\n",
    "print(\"x_te,    nr sample {}, nr feature {}\".format(x_te.shape[0],x_te.shape[1]))\n",
    "print(\"Tr: Pos {} Neg {}\".format(y_train[y_train==1].shape[0],y_train[y_train==0].shape[0]))\n",
    "print(\"Va: Pos {} Neg {}\".format(y_va[y_va==1].shape[0],y_va[y_va==0].shape[0]))\n",
    "print(\"Te: Pos {} Neg {}\".format(y_te[y_te==1].shape[0],y_te[y_te==0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tr_sample = x_train.shape[0]\n",
    "sample_ratio = 0.6\n",
    "obj_sample_size = int(sample_ratio * num_tr_sample)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Our unweighted method can downweight the bad cases which cause high test loss to the our model, which is an important reason of its ability to improve result with less data.\n",
    "To show the performance of our methods in noisy label situation, we perform addtional experiments with some training\n",
    "labels being flipped. The results show the enlarging superiority of our subsampling methods \n",
    "\"\"\"\n",
    "\n",
    "# flip labels\n",
    "idxs = np.arange(y_train.shape[0])\n",
    "flip_ratio = 0.4\n",
    "np.random.shuffle(idxs)\n",
    "num_flip = int(flip_ratio * len(idxs))\n",
    "y_train[idxs[:num_flip]] = np.logical_xor(np.ones(num_flip), y_train[idxs[:num_flip]]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]iter  1 act 1.784e+01 pre 1.766e+01 delta 2.238e-01 f 5.770e+02 |g| 2.249e+02 CG   4\n",
      "cg reaches trust region boundary\n",
      "iter  2 act 1.948e+00 pre 1.946e+00 delta 2.357e-01 f 5.592e+02 |g| 2.199e+01 CG   4\n",
      "cg reaches trust region boundary\n",
      "iter  3 act 2.042e+00 pre 2.040e+00 delta 3.111e-01 f 5.573e+02 |g| 2.639e+01 CG   5\n",
      "cg reaches trust region boundary\n",
      "iter  4 act 1.871e+00 pre 1.869e+00 delta 4.825e-01 f 5.552e+02 |g| 1.447e+01 CG   5\n",
      "cg reaches trust region boundary\n",
      "iter  5 act 1.743e+00 pre 1.738e+00 delta 5.484e-01 f 5.533e+02 |g| 1.329e+01 CG   6\n",
      "cg reaches trust region boundary\n",
      "iter  6 act 1.800e+00 pre 1.791e+00 delta 6.828e-01 f 5.516e+02 |g| 1.205e+01 CG   7\n",
      "cg reaches trust region boundary\n",
      "iter  7 act 1.148e+00 pre 1.147e+00 delta 7.735e-01 f 5.498e+02 |g| 1.293e+01 CG   8\n",
      "iter  8 act 5.453e-01 pre 5.448e-01 delta 7.735e-01 f 5.487e+02 |g| 5.447e+00 CG  16\n",
      "iter  9 act 1.441e-02 pre 1.441e-02 delta 7.735e-01 f 5.481e+02 |g| 5.371e-01 CG  25\n",
      "iter 10 act 1.435e-04 pre 1.435e-04 delta 7.735e-01 f 5.481e+02 |g| 4.869e-02 CG  27\n",
      "iter 11 act 7.211e-07 pre 7.211e-07 delta 7.735e-01 f 5.481e+02 |g| 4.112e-03 CG  25\n",
      "iter 12 act 7.139e-09 pre 7.136e-09 delta 7.735e-01 f 5.481e+02 |g| 3.614e-04 CG  27\n",
      "iter 13 act 3.251e-11 pre 3.545e-11 delta 7.735e-01 f 5.481e+02 |g| 3.199e-05 CG  23\n",
      "WARNING: actred and prered too small\n",
      "[FullSet] Va logloss 0.525831\n",
      "[FullSet] Te logloss 0.522210\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define the full-set-model \n",
    "\n",
    "\"\"\" \n",
    "model : logistic regression:\n",
    "C: Inverse of regularization strength. smaller values specify stronger regularization.\n",
    "fit_intercept: constant (a.k.a. bias or intercept) should be added to the decision function.\n",
    "tol: Tolerance for stopping criteria.\n",
    "solver: Algorithm to use in the optimization problem.For small datasets, ‘liblinear’ is a good choice\n",
    "multi_class: ‘ovr’, then a binary problem is fit for each label.\n",
    "max_iterint: Maximum number of iterations taken for the solvers to converge\n",
    "\"\"\"\n",
    "\n",
    "clf = LogisticRegression(\n",
    "        C = C,\n",
    "        fit_intercept=False,\n",
    "        tol = 1e-8,\n",
    "        solver=\"liblinear\",\n",
    "        multi_class=\"ovr\",\n",
    "        max_iter=100,\n",
    "        warm_start=False,\n",
    "        verbose=1,\n",
    "        )\n",
    "\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "# on Va\n",
    "\n",
    "y_va_pred = clf.predict_proba(x_va)[:,1] \n",
    "#predict_proba : Probability estimates. The returned estimates for all classes are ordered by the label of classes.\n",
    "full_logloss = log_loss(y_va,y_va_pred) \n",
    "#Log loss, aka logistic loss or cross-entropy loss. This is the loss function defined as the negative log-likelihood of a logistic model that returns y_pred probabilities for its training data y_true. \n",
    "#For a single sample with true label yt in {0,1} and estimated probability yp that yt = 1, the log loss is\n",
    "#-log P(yt|yp) = -(yt log(yp) + (1 - yt) log(1 - yp))\n",
    "weight_ar = clf.coef_.flatten() \n",
    "#Coefficient of the features in the decision function. coef_ is of shape (1, n_features) when the given problem is binary.\n",
    "\n",
    "# on Te\n",
    "\n",
    "y_te_pred = clf.predict_proba(x_te)[:,1]\n",
    "full_te_logloss = log_loss(y_te,y_te_pred)\n",
    "full_te_auc = roc_auc_score(y_te, y_te_pred)\n",
    "#The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.\n",
    "# The true-positive rate is also known as sensitivity, recall or probability of detection\n",
    "# The false-positive rate is also known as probability of false alarm \n",
    "# AUC measures how true positive rate (recall) and false positive rate trade off\n",
    "\n",
    "y_te_pred = clf.predict(x_te)\n",
    "full_te_acc = (y_te == y_te_pred).sum() / y_te.shape[0]\n",
    "\n",
    "\n",
    "# print full-set-model results\n",
    "print(\"[FullSet] Va logloss {:.6f}\".format(full_logloss))\n",
    "print(\"[FullSet] Te logloss {:.6f}\".format(full_te_logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_logloss_theta_lr(label,ypred,x,C=0.03,has_l2=True,scale_factor=1.0):\n",
    "    \"\"\"Return d l_i / d_theta = d l_i / d_ypred * d y_pred / d theta\n",
    "        grad_logloss_theta: gradient on the theta, shape: [n,]\n",
    "    \"\"\"\n",
    "    # The isinstance() function returns True if the specified object is of the specified type, otherwise False.\n",
    "    if not isinstance(label,np.ndarray) or not isinstance(ypred,np.ndarray):\n",
    "        label = np.array(label).flatten()\n",
    "        ypred = np.array(ypred).flatten()\n",
    "\n",
    "\n",
    "    grad_logloss_theta = C * x.T.dot(ypred-label)\n",
    "\n",
    "    return scale_factor * grad_logloss_theta\n",
    "\n",
    "def batch_grad_logloss_lr(label,ypred,x,C=0.03,scale_factor=1.0):\n",
    "    \"\"\"Return gradient on a batch.\n",
    "        batch_grad: gradient of each sample on parameters,\n",
    "            has shape [None,n]\n",
    "    \"\"\"\n",
    "    diffs = ypred - label\n",
    "    if isinstance(x,np.ndarray):\n",
    "        diffs = diffs.reshape(-1,1)\n",
    "        batch_grad = x * diffs\n",
    "    else:\n",
    "        diffs = sparse.diags(diffs)\n",
    "        batch_grad = x.T.dot(diffs).T\n",
    "    batch_grad = sparse.csr_matrix(C * batch_grad)      \n",
    "    return scale_factor * batch_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pnans/Documents/GitHub/Unweighted-Data-Subsampling-via-Influence-Function/inverse_hvp.py:146: OptimizeWarning: Unknown solver options: preconditioner\n",
      "  fmin_results = fmin_ncg(f=fmin_loss_fn,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed in getting the inverse of preconditioner M.\n",
      "iter 0 cg iter 0 iter_diff 4305.735512646801\n",
      "Function value: -360480.4532690004\n",
      "Split function value: 363857.5355531955, -724337.9888221959\n",
      "iter 1 cg iter 0 iter_diff 994.9107666369654\n",
      "Function value: -402211.57174907194\n",
      "Split function value: 372196.4301940192, -774408.0019430912\n",
      "iter 2 cg iter 0 iter_diff 480.3468302419942\n",
      "Function value: -437606.79833226895\n",
      "Split function value: 439776.61213072226, -877383.4104629912\n",
      "iter 3 cg iter 0 iter_diff 203.96676376517718\n",
      "iter 3 cg iter 10 iter_diff 103.06986903307417\n",
      "Function value: -469177.5246129272\n",
      "Split function value: 476194.82317021757, -945372.3477831448\n",
      "iter 4 cg iter 0 iter_diff 79.42536795709998\n",
      "iter 4 cg iter 10 iter_diff 46.498857427336254\n",
      "Function value: -475866.23644338455\n",
      "Split function value: 465757.77973365155, -941624.0161770361\n",
      "iter 5 cg iter 0 iter_diff 33.34395773833848\n",
      "iter 5 cg iter 10 iter_diff 16.0987010186897\n",
      "Function value: -476560.76464876404\n",
      "Split function value: 473982.8922486623, -950543.6568974264\n",
      "iter 6 cg iter 0 iter_diff 16.098701018689077\n",
      "iter 6 cg iter 10 iter_diff 10.339522391149817\n",
      "Function value: -476817.94054725685\n",
      "Split function value: 476369.62417307135, -953187.5647203282\n",
      "iter 7 cg iter 0 iter_diff 5.8069878465661855\n",
      "Function value: -476835.51161267306\n",
      "Split function value: 476488.94168038666, -953324.4532930597\n",
      "iter 8 cg iter 0 iter_diff 2.207735779429986\n",
      "iter 8 cg iter 10 iter_diff 2.2667747643270237\n",
      "Function value: -476841.3134901144\n",
      "Split function value: 476897.10139419185, -953738.4148843063\n",
      "iter 9 cg iter 0 iter_diff 1.0570202251841785\n",
      "iter 9 cg iter 10 iter_diff 0.48117183730579327\n",
      "Function value: -476842.2813511372\n",
      "Split function value: 476761.99276343803, -953604.2741145752\n",
      "iter 10 cg iter 0 iter_diff 0.4811718373069077\n",
      "iter 10 cg iter 10 iter_diff 0.36347655073304075\n",
      "Function value: -476842.65113994473\n",
      "Split function value: 476862.51510785293, -953705.1662477977\n",
      "iter 11 cg iter 0 iter_diff 0.19879928522084192\n",
      "Function value: -476842.6665751763\n",
      "Split function value: 476848.6729853306, -953691.3395605069\n",
      "iter 12 cg iter 0 iter_diff 0.07384474105934571\n",
      "iter 12 cg iter 10 iter_diff 0.033391345950662815\n",
      "Function value: -476842.6725223932\n",
      "Split function value: 476840.8637468419, -953683.5362692351\n",
      "iter 13 cg iter 0 iter_diff 0.017922565293669007\n",
      "iter 13 cg iter 10 iter_diff 0.021166967018107743\n",
      "iter 13 cg iter 20 iter_diff 0.003109780931759696\n",
      "Function value: -476842.6731416618\n",
      "Split function value: 476842.43528704764, -953685.1084287094\n",
      "iter 14 cg iter 0 iter_diff 0.00146866034242501\n",
      "iter 14 cg iter 10 iter_diff 0.00044819104212612525\n",
      "iter 14 cg iter 20 iter_diff 0.0003501297024604792\n",
      "Function value: -476842.67314456776\n",
      "Split function value: 476842.67331056437, -953685.3464551321\n",
      "iter 15 cg iter 0 iter_diff 4.101644814237675e-05\n",
      "iter 15 cg iter 10 iter_diff 1.6946023245622383e-05\n",
      "iter 15 cg iter 20 iter_diff 1.1025520516437915e-05\n",
      "Function value: -476842.6731445708\n",
      "Split function value: 476842.67337663425, -953685.346521205\n",
      "iter 16 cg iter 0 iter_diff 6.044899767364521e-06\n",
      "iter 16 cg iter 10 iter_diff 3.6240777932306504e-06\n",
      "Function value: -476842.673144571\n",
      "Split function value: 476842.6732926832, -953685.3464372542\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -476842.673145\n",
      "         Iterations: 17\n",
      "         Function evaluations: 81\n",
      "         Gradient evaluations: 94\n",
      "         Hessian evaluations: 211\n",
      "Inverse HVP took 24.2 sec\n",
      "============================================================\n",
      "IF(influence function) Stats: mean -1.3193588941, max 748.7852101516, min -983.3977022934\n"
     ]
    }
   ],
   "source": [
    "# building precoditioner\n",
    "test_grad_loss_val = grad_logloss_theta_lr(y_va,y_va_pred,x_va,C,0.1/(num_tr_sample*C))  #Return d l_i / d_theta\n",
    "\n",
    "tr_pred = clf.predict_proba(x_train)[:,1]\n",
    "batch_size = 10000\n",
    "M = None\n",
    "total_batch = int(np.ceil(num_tr_sample / float(batch_size)))\n",
    "\n",
    "for idx in range(total_batch):\n",
    "    batch_tr_grad = batch_grad_logloss_lr(y_train[idx*batch_size:(idx+1)*batch_size],\n",
    "        tr_pred[idx*batch_size:(idx+1)*batch_size],\n",
    "        x_train[idx*batch_size:(idx+1)*batch_size],\n",
    "        C,\n",
    "        1.0)\n",
    "\n",
    "    sum_grad = batch_tr_grad.multiply(x_train[idx*batch_size:(idx+1)*batch_size]).sum(0)\n",
    "    if M is None:\n",
    "        M = sum_grad\n",
    "    else:\n",
    "        M = M + sum_grad       \n",
    "M = M + 0.1/(num_tr_sample*C) * np.ones(x_train.shape[1])\n",
    "M = np.array(M).flatten()\n",
    "\n",
    "# computing the inverse Hessian-vector-product\n",
    "#The Hessian Matrix is a square matrix of second ordered partial derivatives of a scalar function.\n",
    "#It is of immense use in linear algebra as well as for determining points of local maxima or minima\n",
    "iv_hvp = inverse_hvp_lr_newtonCG(x_train,y_train,tr_pred,test_grad_loss_val,C,True,1e-5,True,M,0.1/(num_tr_sample*C))\n",
    "\n",
    "# get influence score\n",
    "total_batch = int(np.ceil(x_train.shape[0] / float(batch_size)))\n",
    "predicted_loss_diff = []\n",
    "for idx in range(total_batch):\n",
    "    train_grad_loss_val = batch_grad_logloss_lr(y_train[idx*batch_size:(idx+1)*batch_size],\n",
    "        tr_pred[idx*batch_size:(idx+1)*batch_size],\n",
    "        x_train[idx*batch_size:(idx+1)*batch_size],\n",
    "        C,\n",
    "        1.0)\n",
    "    predicted_loss_diff.extend(np.array(train_grad_loss_val.dot(iv_hvp)).flatten())    \n",
    "predicted_loss_diffs = np.asarray(predicted_loss_diff)\n",
    "\n",
    "print(\"==\"*30)\n",
    "print(\"IF(influence function) Stats: mean {:.10f}, max {:.10f}, min {:.10f}\".format(\n",
    "    predicted_loss_diffs.mean(), predicted_loss_diffs.max(), predicted_loss_diffs.min())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_from_one_class(y_train,prob_pi,label,ratio):\n",
    "    # select positive and negative samples respectively\n",
    "    num_sample = y_train[y_train==label].shape[0]\n",
    "    all_idx = np.arange(y_train.shape[0])[y_train==label]\n",
    "    label_prob_pi = prob_pi[all_idx]\n",
    "    obj_sample_size = int(ratio * num_sample)\n",
    "\n",
    "    sb_idx = None\n",
    "    iteration = 0\n",
    "    while True:\n",
    "        rand_prob = np.random.rand(num_sample)\n",
    "        iter_idx = all_idx[rand_prob < label_prob_pi]\n",
    "        if sb_idx is None:\n",
    "            sb_idx = iter_idx\n",
    "        else:\n",
    "            new_idx = np.setdiff1d(iter_idx, sb_idx)\n",
    "            diff_size = obj_sample_size - sb_idx.shape[0]\n",
    "            if new_idx.shape[0] < diff_size:\n",
    "                sb_idx = np.union1d(iter_idx, sb_idx)\n",
    "            else:\n",
    "                new_idx = np.random.choice(new_idx, diff_size, replace=False)\n",
    "                sb_idx = np.union1d(sb_idx, new_idx)\n",
    "        iteration += 1\n",
    "        if sb_idx.shape[0] >= obj_sample_size:\n",
    "            sb_idx = np.random.choice(sb_idx,obj_sample_size,replace=False)\n",
    "            return sb_idx\n",
    "\n",
    "        if iteration > 100:\n",
    "            diff_size = obj_sample_size - sb_idx.shape[0]\n",
    "            leave_idx = np.setdiff1d(all_idx, sb_idx)\n",
    "            # left samples are sorted by their IF\n",
    "            # leave_idx = leave_idx[np.argsort(prob_pi[leave_idx])[-diff_size:]]\n",
    "            leave_idx = np.random.choice(leave_idx,diff_size,replace=False)\n",
    "            sb_idx = np.union1d(sb_idx, leave_idx)\n",
    "            return sb_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi Stats: [0.08010065 0.1627333  0.66298381 0.79176391 0.8593959 ]\n"
     ]
    }
   ],
   "source": [
    "# build sampling probability\n",
    "\n",
    "sigmoid_k = 10  # parameter for the sigmoid sampling function\n",
    "phi_ar = - predicted_loss_diffs\n",
    "IF_interval = phi_ar.max() - phi_ar.min()\n",
    "a_param = sigmoid_k / IF_interval\n",
    "prob_pi = 1 / (1 + np.exp(a_param * phi_ar))\n",
    "print(\"Pi Stats:\",np.percentile(prob_pi,[10,25,50,75,90]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_idx = select_from_one_class(y_train,prob_pi,1,sample_ratio)\n",
    "neg_idx = select_from_one_class(y_train,prob_pi,0,sample_ratio)\n",
    "sb_idx = np.union1d(pos_idx,neg_idx)\n",
    "sb_x_train = x_train[sb_idx]\n",
    "sb_y_train = y_train[sb_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]iter  1 act 1.246e+02 pre 1.145e+02 delta 5.750e-01 f 3.462e+02 |g| 4.817e+02 CG   3\n",
      "cg reaches trust region boundary\n",
      "iter  2 act 1.454e+01 pre 1.312e+01 delta 6.991e-01 f 2.216e+02 |g| 8.830e+01 CG   4\n",
      "cg reaches trust region boundary\n",
      "iter  3 act 4.924e+00 pre 4.722e+00 delta 8.327e-01 f 2.070e+02 |g| 2.178e+01 CG   4\n",
      "cg reaches trust region boundary\n",
      "iter  4 act 3.154e+00 pre 3.148e+00 delta 9.560e-01 f 2.021e+02 |g| 1.198e+01 CG   5\n",
      "cg reaches trust region boundary\n",
      "iter  5 act 2.026e+00 pre 1.978e+00 delta 1.016e+00 f 1.990e+02 |g| 7.115e+00 CG   7\n",
      "iter  6 act 8.089e-01 pre 8.088e-01 delta 1.016e+00 f 1.969e+02 |g| 4.989e+00 CG  13\n",
      "iter  7 act 1.580e-02 pre 1.578e-02 delta 1.016e+00 f 1.961e+02 |g| 8.397e-01 CG  14\n",
      "iter  8 act 3.571e-04 pre 3.571e-04 delta 1.016e+00 f 1.961e+02 |g| 6.139e-02 CG  18\n",
      "iter  9 act 1.186e-06 pre 1.186e-06 delta 1.016e+00 f 1.961e+02 |g| 5.604e-03 CG  14\n",
      "iter 10 act 2.320e-08 pre 2.320e-08 delta 1.016e+00 f 1.961e+02 |g| 5.316e-04 CG  16\n",
      "iter 11 act 1.363e-10 pre 1.357e-10 delta 1.016e+00 f 1.961e+02 |g| 4.436e-05 CG  16\n",
      "WARNING: actred and prered too small\n"
     ]
    }
   ],
   "source": [
    "clf.fit(sb_x_train,sb_y_train)\n",
    "y_va_pred = clf.predict_proba(x_va)[:,1]\n",
    "sb_logloss = log_loss(y_va, y_va_pred)\n",
    "sb_weight = clf.coef_.flatten()\n",
    "diff_w_norm = np.linalg.norm(weight_ar - sb_weight)\n",
    "sb_size = sb_x_train.shape[0]\n",
    "y_te_pred = clf.predict_proba(x_te)[:,1]\n",
    "sb_te_logloss = log_loss(y_te,y_te_pred)\n",
    "sb_te_auc = roc_auc_score(y_te, y_te_pred)\n",
    "y_te_pred = clf.predict(x_te)\n",
    "sb_te_acc = (y_te == y_te_pred).sum() / y_te.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]iter  1 act 1.276e+01 pre 1.258e+01 delta 4.898e-01 f 3.462e+02 |g| 1.361e+02 CG   5\n",
      "cg reaches trust region boundary\n",
      "iter  2 act 2.358e+00 pre 2.373e+00 delta 5.391e-01 f 3.335e+02 |g| 1.261e+01 CG   5\n",
      "cg reaches trust region boundary\n",
      "iter  3 act 2.198e+00 pre 2.183e+00 delta 6.885e-01 f 3.311e+02 |g| 1.069e+01 CG   6\n",
      "cg reaches trust region boundary\n",
      "iter  4 act 1.393e+00 pre 1.391e+00 delta 7.241e-01 f 3.289e+02 |g| 6.927e+00 CG   7\n",
      "cg reaches trust region boundary\n",
      "iter  5 act 1.037e+00 pre 1.031e+00 delta 7.585e-01 f 3.275e+02 |g| 7.856e+00 CG   9\n",
      "iter  6 act 2.424e-01 pre 2.424e-01 delta 7.585e-01 f 3.265e+02 |g| 4.735e+00 CG  14\n",
      "iter  7 act 7.395e-03 pre 7.395e-03 delta 7.585e-01 f 3.262e+02 |g| 3.683e-01 CG  20\n",
      "iter  8 act 5.608e-05 pre 5.608e-05 delta 7.585e-01 f 3.262e+02 |g| 3.337e-02 CG  22\n",
      "iter  9 act 3.056e-07 pre 3.056e-07 delta 7.585e-01 f 3.262e+02 |g| 2.430e-03 CG  19\n",
      "iter 10 act 4.799e-09 pre 4.799e-09 delta 7.585e-01 f 3.262e+02 |g| 2.403e-04 CG  21\n",
      "iter 11 act 2.581e-11 pre 2.438e-11 delta 7.585e-01 f 3.262e+02 |g| 2.216e-05 CG  18\n",
      "WARNING: actred and prered too small\n"
     ]
    }
   ],
   "source": [
    "# baseline model: random sampling\n",
    "\n",
    "u_idxs = np.arange(x_train.shape[0])\n",
    "uniform_idxs = np.random.choice(u_idxs,obj_sample_size,replace=False)\n",
    "us_x_train = x_train[uniform_idxs]\n",
    "us_y_train = y_train[uniform_idxs]\n",
    "clf.fit(us_x_train, us_y_train)\n",
    "y_va_pred = clf.predict_proba(x_va)[:,1]\n",
    "us_logloss = log_loss(y_va, y_va_pred)\n",
    "us_size = us_x_train.shape[0]\n",
    "y_te_pred = clf.predict_proba(x_te)[:,1]\n",
    "us_te_logloss = log_loss(y_te,y_te_pred)\n",
    "us_te_auc = roc_auc_score(y_te, y_te_pred)\n",
    "y_te_pred = clf.predict(x_te)\n",
    "us_te_acc = (y_te == y_te_pred).sum() / y_te.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Result Summary on Va\n",
      "[UIDS]  logloss 0.162497, # 4994\n",
      "[Random]   logloss 0.527064, # 4995\n",
      "[Full]     logloss 0.525831, # 8325\n",
      "Result Summary on Te\n",
      "[UIDS]  logloss 0.176543, # 4994\n",
      "[Random]   logloss 0.524031, # 4995\n",
      "[Full]     logloss 0.522210, # 8325\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"==\"*30)\n",
    "print(\"Result Summary on Va\")\n",
    "print(\"[UIDS]  logloss {:.6f}, # {}\".format(sb_logloss,sb_size))\n",
    "print(\"[Random]   logloss {:.6f}, # {}\".format(us_logloss,us_size))\n",
    "print(\"[Full]     logloss {:.6f}, # {}\".format(full_logloss,num_tr_sample))\n",
    "\n",
    "print(\"Result Summary on Te\")\n",
    "print(\"[UIDS]  logloss {:.6f}, # {}\".format(sb_te_logloss,sb_size))\n",
    "print(\"[Random]   logloss {:.6f}, # {}\".format(us_te_logloss,us_size))\n",
    "print(\"[Full]     logloss {:.6f}, # {}\".format(full_te_logloss,num_tr_sample))\n",
    "print(\"==\"*30)\n",
    "# Attention: if the dataset used here is small, one experiment may fail because of uncertainty of subsampling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Result Summary on Te (ACC and AUC)\n",
      "[UIDS]  acc 0.984281, auc 0.998802 # 4994\n",
      "[Random]   acc 0.900139, auc 0.950359 # 4995\n",
      "[Full]     acc 0.916782, auc 0.961824 # 8325\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"==\"*30)\n",
    "print(\"Result Summary on Te (ACC and AUC)\")\n",
    "print(\"[UIDS]  acc {:.6f}, auc {:.6f} # {}\".format(sb_te_acc,sb_te_auc, sb_size))\n",
    "print(\"[Random]   acc {:.6f}, auc {:.6f} # {}\".format(us_te_acc,us_te_auc, us_size))\n",
    "print(\"[Full]     acc {:.6f}, auc {:.6f} # {}\".format(full_te_acc,full_te_auc, num_tr_sample))\n",
    "print(\"==\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_image\n",
    "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
    "explainer = lime_image.LimeImageExplainer(verbose = False)\n",
    "segmenter = SegmentationAlgorithm('quickshift', kernel_size=1, max_dist=200, ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (784,) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/pnans/Documents/GitHub/Unweighted-Data-Subsampling-via-Influence-Function/combine_through_influence.ipynb Cell 17\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pnans/Documents/GitHub/Unweighted-Data-Subsampling-via-Influence-Function/combine_through_influence.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pnans/Documents/GitHub/Unweighted-Data-Subsampling-via-Influence-Function/combine_through_influence.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m fig, ax1 \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/pnans/Documents/GitHub/Unweighted-Data-Subsampling-via-Influence-Function/combine_through_influence.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ax1\u001b[39m.\u001b[39;49mimshow(x_te[\u001b[39m0\u001b[39;49m], interpolation \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mnone\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pnans/Documents/GitHub/Unweighted-Data-Subsampling-via-Influence-Function/combine_through_influence.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ax1\u001b[39m.\u001b[39mset_title(\u001b[39m'\u001b[39m\u001b[39mDigit: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(y_te[\u001b[39m0\u001b[39m]))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/__init__.py:1447\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1444\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   1445\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1446\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1447\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1449\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1450\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   1451\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/axes/_axes.py:5523\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5518\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m   5519\u001b[0m im \u001b[39m=\u001b[39m mimage\u001b[39m.\u001b[39mAxesImage(\u001b[39mself\u001b[39m, cmap, norm, interpolation, origin, extent,\n\u001b[1;32m   5520\u001b[0m                       filternorm\u001b[39m=\u001b[39mfilternorm, filterrad\u001b[39m=\u001b[39mfilterrad,\n\u001b[1;32m   5521\u001b[0m                       resample\u001b[39m=\u001b[39mresample, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 5523\u001b[0m im\u001b[39m.\u001b[39;49mset_data(X)\n\u001b[1;32m   5524\u001b[0m im\u001b[39m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5525\u001b[0m \u001b[39mif\u001b[39;00m im\u001b[39m.\u001b[39mget_clip_path() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5526\u001b[0m     \u001b[39m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/image.py:711\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A[:, :, \u001b[39m0\u001b[39m]\n\u001b[1;32m    709\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    710\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39min\u001b[39;00m [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m]):\n\u001b[0;32m--> 711\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid shape \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m for image data\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    712\u001b[0m                     \u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mshape))\n\u001b[1;32m    714\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m    715\u001b[0m     \u001b[39m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    716\u001b[0m     \u001b[39m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    717\u001b[0m     \u001b[39m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    718\u001b[0m     \u001b[39m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    719\u001b[0m     high \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39minteger) \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (784,) for image data"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAMbElEQVR4nO3bcYikd33H8ffHXFOpjbGYFeTuNJFeqldbMF1Si1BTTMslhbs/LHIHobUED62RglJIsaQS/7JSC8K19kpDVDDx9I+y4EmgNiEQPM2GaPQuRNbTNhelOTXNP8HE0G//mEk72e/uzZO72Znb+n7BwjzP/Hbmu8PwvmeeeS5VhSRNetmiB5B08TEMkhrDIKkxDJIawyCpMQySmqlhSHJHkieTfHuT+5Pkk0nWkjyS5JrZjylpnoYcMdwJ7DvH/TcAe8Y/h4F/uPCxJC3S1DBU1f3AT86x5ADwmRo5AbwqyWtnNaCk+dsxg8fYCTw+sX1mvO+H6xcmOczoqIJXvOIVv/XGN75xBk8vaTMPPfTQj6pq6aX+3izCMFhVHQWOAiwvL9fq6uo8n176uZPk38/n92bxrcQTwO6J7V3jfZK2qVmEYQX44/G3E28Fnq6q9jFC0vYx9aNEkruA64ArkpwB/hr4BYCq+hRwHLgRWAOeAf50q4aVNB9Tw1BVh6bcX8D7ZzaRpIXzykdJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBknNoDAk2ZfksSRrSW7d4P7XJbk3ycNJHkly4+xHlTQvU8OQ5BLgCHADsBc4lGTvumV/BRyrqrcAB4G/n/WgkuZnyBHDtcBaVZ2uqueAu4ED69YU8Mrx7cuBH8xuREnzNiQMO4HHJ7bPjPdN+ghwU5IzwHHgAxs9UJLDSVaTrJ49e/Y8xpU0D7M6+XgIuLOqdgE3Ap9N0h67qo5W1XJVLS8tLc3oqSXN2pAwPAHsntjeNd436WbgGEBVfRV4OXDFLAaUNH9DwvAgsCfJVUkuZXRycWXdmv8A3gGQ5E2MwuBnBWmbmhqGqnoeuAW4B3iU0bcPJ5PcnmT/eNmHgPck+SZwF/DuqqqtGlrS1toxZFFVHWd0UnFy320Tt08Bb5vtaJIWxSsfJTWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSMygMSfYleSzJWpJbN1nzriSnkpxM8rnZjilpnnZMW5DkEuAI8PvAGeDBJCtVdWpizR7gL4G3VdVTSV6zVQNL2npDjhiuBdaq6nRVPQfcDRxYt+Y9wJGqegqgqp6c7ZiS5mlIGHYCj09snxnvm3Q1cHWSB5KcSLJvowdKcjjJapLVs2fPnt/EkrbcrE4+7gD2ANcBh4B/SvKq9Yuq6mhVLVfV8tLS0oyeWtKsDQnDE8Duie1d432TzgArVfWzqvoe8B1GoZC0DQ0Jw4PAniRXJbkUOAisrFvzL4yOFkhyBaOPFqdnN6akeZoahqp6HrgFuAd4FDhWVSeT3J5k/3jZPcCPk5wC7gX+oqp+vFVDS9paqaqFPPHy8nKtrq4u5LmlnxdJHqqq5Zf6e175KKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqRkUhiT7kjyWZC3JredY984klWR5diNKmrepYUhyCXAEuAHYCxxKsneDdZcBfw58bdZDSpqvIUcM1wJrVXW6qp4D7gYObLDuo8DHgJ/OcD5JCzAkDDuBxye2z4z3/a8k1wC7q+pL53qgJIeTrCZZPXv27EseVtJ8XPDJxyQvAz4BfGja2qo6WlXLVbW8tLR0oU8taYsMCcMTwO6J7V3jfS+4DHgzcF+S7wNvBVY8ASltX0PC8CCwJ8lVSS4FDgIrL9xZVU9X1RVVdWVVXQmcAPZX1eqWTCxpy00NQ1U9D9wC3AM8ChyrqpNJbk+yf6sHlDR/O4YsqqrjwPF1+27bZO11Fz6WpEXyykdJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQMCkOSfUkeS7KW5NYN7v9gklNJHknylSSvn/2okuZlahiSXAIcAW4A9gKHkuxdt+xhYLmqfhP4IvA3sx5U0vwMOWK4FlirqtNV9RxwN3BgckFV3VtVz4w3TwC7ZjumpHkaEoadwOMT22fG+zZzM/Dlje5IcjjJapLVs2fPDp9S0lzN9ORjkpuAZeDjG91fVUerarmqlpeWlmb51JJmaMeANU8Auye2d433vUiS64EPA2+vqmdnM56kRRhyxPAgsCfJVUkuBQ4CK5MLkrwF+Edgf1U9OfsxJc3T1DBU1fPALcA9wKPAsao6meT2JPvHyz4O/DLwhSTfSLKyycNJ2gaGfJSgqo4Dx9ftu23i9vUznkvSAnnlo6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpGZQGJLsS/JYkrUkt25w/y8m+fz4/q8luXLmk0qam6lhSHIJcAS4AdgLHEqyd92ym4GnqupXgb8DPjbrQSXNz5AjhmuBtao6XVXPAXcDB9atOQB8enz7i8A7kmR2Y0qapx0D1uwEHp/YPgP89mZrqur5JE8DrwZ+NLkoyWHg8Hjz2STfPp+hF+QK1v09F7HtNCtsr3m306wAv3Y+vzQkDDNTVUeBowBJVqtqeZ7PfyG207zbaVbYXvNup1lhNO/5/N6QjxJPALsntneN9224JskO4HLgx+czkKTFGxKGB4E9Sa5KcilwEFhZt2YF+JPx7T8C/q2qanZjSpqnqR8lxucMbgHuAS4B7qiqk0luB1aragX4Z+CzSdaAnzCKxzRHL2DuRdhO826nWWF7zbudZoXznDf+wy5pPa98lNQYBknNlodhO11OPWDWDyY5leSRJF9J8vpFzDkxzznnnVj3ziSVZGFfsw2ZNcm7xq/vySSfm/eM62aZ9l54XZJ7kzw8fj/cuIg5x7PckeTJza4Lysgnx3/LI0mumfqgVbVlP4xOVn4XeANwKfBNYO+6NX8GfGp8+yDw+a2c6QJn/T3gl8a337eoWYfOO153GXA/cAJYvlhnBfYADwO/Mt5+zcX82jI6qfe+8e29wPcXOO/vAtcA397k/huBLwMB3gp8bdpjbvURw3a6nHrqrFV1b1U9M948weiajkUZ8toCfJTR/1356TyHW2fIrO8BjlTVUwBV9eScZ5w0ZN4CXjm+fTnwgznO9+JBqu5n9G3gZg4An6mRE8Crkrz2XI+51WHY6HLqnZutqarngRcup563IbNOuplRhRdl6rzjQ8bdVfWleQ62gSGv7dXA1UkeSHIiyb65TdcNmfcjwE1JzgDHgQ/MZ7Tz8lLf2/O9JPr/iyQ3AcvA2xc9y2aSvAz4BPDuBY8y1A5GHyeuY3Qkdn+S36iq/1rkUOdwCLizqv42ye8wuo7nzVX134sebBa2+ohhO11OPWRWklwPfBjYX1XPzmm2jUyb9zLgzcB9Sb7P6LPlyoJOQA55bc8AK1X1s6r6HvAdRqFYhCHz3gwcA6iqrwIvZ/QfrC5Gg97bL7LFJ0V2AKeBq/i/kzi/vm7N+3nxycdjCzqBM2TWtzA6KbVnETO+1HnXrb+PxZ18HPLa7gM+Pb59BaND31dfxPN+GXj3+PabGJ1jyALfD1ey+cnHP+TFJx+/PvXx5jDwjYzq/13gw+N9tzP6FxdGpf0CsAZ8HXjDAl/cabP+K/CfwDfGPyuLmnXIvOvWLiwMA1/bMProcwr4FnDwYn5tGX0T8cA4Gt8A/mCBs94F/BD4GaMjr5uB9wLvnXhtj4z/lm8NeR94SbSkxisfJTWGQVJjGCQ1hkFSYxgkNYZBUmMYJDX/AwqkUdVj8DQ4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "fig, ax1 = plt.subplots(1,1)\n",
    "ax1.imshow(x_te[0], interpolation = 'none')\n",
    "ax1.set_title('Digit: {}'.format(y_te[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input array must have a shape == (..., 3)), got (1, 784, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/lime/lime_image.py:184\u001b[0m, in \u001b[0;36mLimeImageExplainer.explain_instance\u001b[0;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed)\u001b[0m\n\u001b[1;32m    182\u001b[0m     segments \u001b[39m=\u001b[39m segmentation_fn(image)\n\u001b[1;32m    183\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 184\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    186\u001b[0m fudged_image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    187\u001b[0m \u001b[39mif\u001b[39;00m hide_color \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/lime/lime_image.py:182\u001b[0m, in \u001b[0;36mLimeImageExplainer.explain_instance\u001b[0;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed)\u001b[0m\n\u001b[1;32m    178\u001b[0m     segmentation_fn \u001b[39m=\u001b[39m SegmentationAlgorithm(\u001b[39m'\u001b[39m\u001b[39mquickshift\u001b[39m\u001b[39m'\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m,\n\u001b[1;32m    179\u001b[0m                                             max_dist\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m, ratio\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,\n\u001b[1;32m    180\u001b[0m                                             random_seed\u001b[39m=\u001b[39mrandom_seed)\n\u001b[1;32m    181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     segments \u001b[39m=\u001b[39m segmentation_fn(image)\n\u001b[1;32m    183\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    184\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/lime/wrappers/scikit_image.py:117\u001b[0m, in \u001b[0;36mSegmentationAlgorithm.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_fn(args[\u001b[39m0\u001b[39;49m], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_params)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/skimage/segmentation/_quickshift.py:63\u001b[0m, in \u001b[0;36mquickshift\u001b[0;34m(image, ratio, kernel_size, max_dist, return_tree, sigma, convert2lab, random_seed)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[39mif\u001b[39;00m image\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m     62\u001b[0m         \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mOnly RGB images can be converted to Lab space.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m     image \u001b[39m=\u001b[39m rgb2lab(image)\n\u001b[1;32m     65\u001b[0m \u001b[39mif\u001b[39;00m kernel_size \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     66\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`kernel_size` should be >= 1.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/skimage/color/colorconv.py:1073\u001b[0m, in \u001b[0;36mrgb2lab\u001b[0;34m(rgb, illuminant, observer)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrgb2lab\u001b[39m(rgb, illuminant\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mD65\u001b[39m\u001b[39m\"\u001b[39m, observer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m2\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   1036\u001b[0m     \u001b[39m\"\"\"Conversion from the sRGB color space (IEC 61966-2-1:1999)\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[39m    to the CIE Lab colorspace under the given illuminant and observer.\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[39m    .. [1] https://en.wikipedia.org/wiki/Standard_illuminant\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1073\u001b[0m     \u001b[39mreturn\u001b[39;00m xyz2lab(rgb2xyz(rgb), illuminant, observer)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/skimage/color/colorconv.py:657\u001b[0m, in \u001b[0;36mrgb2xyz\u001b[0;34m(rgb)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[39m\"\"\"RGB to XYZ color space conversion.\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \n\u001b[1;32m    625\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[39m>>> img_xyz = rgb2xyz(img)\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[39m# Follow the algorithm from http://www.easyrgb.com/index.php\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[39m# except we don't multiply/divide by 100 in the conversion\u001b[39;00m\n\u001b[0;32m--> 657\u001b[0m arr \u001b[39m=\u001b[39m _prepare_colorarray(rgb)\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    658\u001b[0m mask \u001b[39m=\u001b[39m arr \u001b[39m>\u001b[39m \u001b[39m0.04045\u001b[39m\n\u001b[1;32m    659\u001b[0m arr[mask] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mpower((arr[mask] \u001b[39m+\u001b[39m \u001b[39m0.055\u001b[39m) \u001b[39m/\u001b[39m \u001b[39m1.055\u001b[39m, \u001b[39m2.4\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/skimage/color/colorconv.py:125\u001b[0m, in \u001b[0;36m_prepare_colorarray\u001b[0;34m(arr, force_copy)\u001b[0m\n\u001b[1;32m    122\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(arr)\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m arr\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInput array must have a shape == (..., 3)), \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgot \u001b[39m\u001b[39m{\u001b[39;00marr\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    128\u001b[0m \u001b[39mreturn\u001b[39;00m dtype\u001b[39m.\u001b[39mimg_as_float(arr, force_copy\u001b[39m=\u001b[39mforce_copy)\n",
      "\u001b[0;31mValueError\u001b[0m: Input array must have a shape == (..., 3)), got (1, 784, 1)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "explanation = explainer.explain_instance(x_te[0], \n",
    "                                         classifier_fn = clf.predict_proba, \n",
    "                                         top_labels=10, hide_color=0, num_samples=1000, segmentation_fn=segmenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86519fbbec93c191aacc49d4c33e96a49fd6ef772decd8151fefe193caa932bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
