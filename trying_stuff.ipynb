{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import gray2rgb, rgb2gray, label2rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import sys\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from inverse_hvp import inverse_hvp_lr_newtonCG\n",
    "import argparse\n",
    "import time\n",
    "import pdb\n",
    "import os\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the dataset used\n",
    "dataset_name = \"mnist\"\n",
    "# regularization parameter for Logistic Regression\n",
    "C = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train-images-idx3-ubyte.gz\n",
      "Extracting train-labels-idx1-ubyte.gz\n",
      "Extracting t10k-images-idx3-ubyte.gz\n",
      "Extracting t10k-labels-idx1-ubyte.gz\n",
      "x_train, nr sample 8325, nr feature 784\n",
      "x_va,    nr sample 3569, nr feature 784\n",
      "x_te,    nr sample 2163, nr feature 784\n",
      "Tr: Pos 4395 Neg 3930\n",
      "Va: Pos 1784 Neg 1785\n",
      "Te: Pos 1135 Neg 1028\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# tool box\n",
    "def load_mnist(validation_size = 5000):\n",
    "    import gzip\n",
    "    def _read32(bytestream):\n",
    "        dt = np.dtype(np.uint32).newbyteorder(\">\")\n",
    "        return np.frombuffer(bytestream.read(4),dtype=dt)[0]\n",
    "\n",
    "    def extract_images(f):\n",
    "        print(\"Extracting\",f.name)\n",
    "        with gzip.GzipFile(fileobj=f) as bytestream:\n",
    "            magic = _read32(bytestream)\n",
    "            num_images = _read32(bytestream)\n",
    "            rows = _read32(bytestream)\n",
    "            cols = _read32(bytestream)\n",
    "            buf = bytestream.read(rows * cols * num_images)\n",
    "            data = np.frombuffer(buf,dtype=np.uint8)\n",
    "            data = data.reshape(num_images,rows,cols,1)\n",
    "            return data\n",
    "    \n",
    "    def extract_labels(f):\n",
    "        print('Extracting', f.name)\n",
    "        with gzip.GzipFile(fileobj=f) as bytestream:\n",
    "            magic = _read32(bytestream)\n",
    "            num_items = _read32(bytestream)\n",
    "            buf = bytestream.read(num_items)\n",
    "            labels = np.frombuffer(buf, dtype=np.uint8)\n",
    "            return labels\n",
    "\n",
    "    #data_dir = \"./data\"\n",
    "    data_dir = \"\"\n",
    "    TRAIN_IMAGES = os.path.join(data_dir,'train-images-idx3-ubyte.gz')\n",
    "    with open(TRAIN_IMAGES,\"rb\") as f:\n",
    "        train_images = extract_images(f)\n",
    "\n",
    "    TRAIN_LABELS =  os.path.join(data_dir,'train-labels-idx1-ubyte.gz')\n",
    "    with open(TRAIN_LABELS,\"rb\") as f:\n",
    "        train_labels = extract_labels(f)\n",
    "\n",
    "    TEST_IMAGES =  os.path.join(data_dir,'t10k-images-idx3-ubyte.gz')\n",
    "    with open(TEST_IMAGES,\"rb\") as f:\n",
    "        test_images = extract_images(f)\n",
    "\n",
    "    TEST_LABELS =  os.path.join(data_dir,'t10k-labels-idx1-ubyte.gz')\n",
    "    with open(TEST_LABELS,\"rb\") as f:\n",
    "        test_labels = extract_labels(f)\n",
    "\n",
    "    # split train and val\n",
    "    train_images = train_images[validation_size:]\n",
    "    train_labels = train_labels[validation_size:]\n",
    "\n",
    "    # preprocessing\n",
    "    train_images = train_images.astype(np.float32) / 255\n",
    "    test_images  = test_images.astype(np.float32) / 255\n",
    "    \n",
    "    # reshape for logistic regression\n",
    "    train_images = np.reshape(train_images, [train_images.shape[0], -1])\n",
    "    test_images = np.reshape(test_images, [test_images.shape[0], -1])\n",
    "    return train_images,train_labels,test_images,test_labels\n",
    "\n",
    "def load_data_two_class(dataset_name,va_ratio):\n",
    "  x_train,y_train,x_test,y_test = load_mnist()\n",
    "  pos_class = 1\n",
    "  neg_class = 7\n",
    "  x_train,y_train = filter_dataset(x_train,y_train,pos_class,neg_class)\n",
    "  x_va,y_va = filter_dataset(x_test,y_test,pos_class,neg_class)\n",
    "  y_va = y_va.astype(int)\n",
    "  y_train = y_train.astype(int)\n",
    "\n",
    "  num_va_sample = int((1-va_ratio) * x_train.shape[0])\n",
    "  x_val = x_train[num_va_sample:]\n",
    "  y_val = y_train[num_va_sample:]\n",
    "  x_train = x_train[:num_va_sample]\n",
    "  y_train = y_train[:num_va_sample]\n",
    "  x_te = x_va\n",
    "  y_te = y_va\n",
    "\n",
    "  return x_train,y_train,x_val,y_val,x_te,y_te\n",
    "\n",
    "\n",
    "def filter_dataset(X, Y, pos_class, neg_class, mode=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Filters out elements of X and Y that aren't one of pos_class or neg_class\n",
    "    then transforms labels of Y so that +1 = pos_class, -1 = neg_class.\n",
    "\n",
    "    They are all 10-classes image classification data sets while Logistic regression can only handle binary classification. we\n",
    "    select the number 1 and 7 as positive and negative classes;\n",
    "    \"\"\"\n",
    "\n",
    "    assert(X.shape[0] == Y.shape[0])\n",
    "    assert(len(Y.shape) == 1)\n",
    "\n",
    "    Y = Y.astype(int)\n",
    "    \n",
    "    pos_idx = Y == pos_class\n",
    "    neg_idx = Y == neg_class        \n",
    "    Y[pos_idx] = 1\n",
    "    Y[neg_idx] = -1\n",
    "    idx_to_keep = pos_idx | neg_idx\n",
    "    X = X[idx_to_keep, ...]\n",
    "    Y = Y[idx_to_keep]\n",
    "    if Y.min() == -1 and mode != \"svm\":\n",
    "        Y = (Y + 1) / 2\n",
    "        Y.astype(int)\n",
    "    return (X, Y)\n",
    "\n",
    "# load data, pick 30% as the Va set\n",
    "x_train,y_train,x_va,y_va,x_te,y_te = load_data_two_class(dataset_name,va_ratio=0.3)\n",
    "\n",
    "\n",
    "\n",
    "print(\"x_train, nr sample {}, nr feature {}\".format(x_train.shape[0],x_train.shape[1]))\n",
    "print(\"x_va,    nr sample {}, nr feature {}\".format(x_va.shape[0],x_va.shape[1]))\n",
    "print(\"x_te,    nr sample {}, nr feature {}\".format(x_te.shape[0],x_te.shape[1]))\n",
    "print(\"Tr: Pos {} Neg {}\".format(y_train[y_train==1].shape[0],y_train[y_train==0].shape[0]))\n",
    "print(\"Va: Pos {} Neg {}\".format(y_va[y_va==1].shape[0],y_va[y_va==0].shape[0]))\n",
    "print(\"Te: Pos {} Neg {}\".format(y_te[y_te==1].shape[0],y_te[y_te==0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tr_sample = x_train.shape[0]\n",
    "sample_ratio = 0.6\n",
    "obj_sample_size = int(sample_ratio * num_tr_sample)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Our unweighted method can downweight the bad cases which cause high test loss to the our model, which is an important reason of its ability to improve result with less data.\n",
    "To show the performance of our methods in noisy label situation, we perform addtional experiments with some training\n",
    "labels being flipped. The results show the enlarging superiority of our subsampling methods \n",
    "\"\"\"\n",
    "\n",
    "# flip labels\n",
    "idxs = np.arange(y_train.shape[0])\n",
    "flip_ratio = 0.4\n",
    "np.random.shuffle(idxs)\n",
    "num_flip = int(flip_ratio * len(idxs))\n",
    "y_train[idxs[:num_flip]] = np.logical_xor(np.ones(num_flip), y_train[idxs[:num_flip]]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "class PipeStep(object):\n",
    "    \"\"\"\n",
    "    Wrapper for turning functions into pipeline transforms (no-fitting)\n",
    "    \"\"\"\n",
    "    def __init__(self, step_func):\n",
    "        self._step_func=step_func\n",
    "    def fit(self,*args):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return self._step_func(X)\n",
    "\n",
    "\n",
    "makegray_step = PipeStep(lambda img_list: [rgb2gray(img) for img in img_list])\n",
    "flatten_step = PipeStep(lambda img_list: [img.ravel() for img in img_list])\n",
    "\n",
    "simple_rf_pipeline = Pipeline([\n",
    "    ('Make Gray', makegray_step),\n",
    "    ('Flatten Image', flatten_step),\n",
    "    #('Normalize', Normalizer()),\n",
    "    #('PCA', PCA(16)),\n",
    "    ('RF', RandomForestClassifier())\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_158689/3157965683.py:17: FutureWarning: Non RGB image conversion is now deprecated. For RGBA images, please use rgb2gray(rgba2rgb(rgb)) instead. In version 0.19, a ValueError will be raised if input image last dimension length is not 3.\n",
      "  makegray_step = PipeStep(lambda img_list: [rgb2gray(img) for img in img_list])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Make Gray', <__main__.PipeStep object at 0x7f7675729b50>),\n",
       "                ('Flatten Image', <__main__.PipeStep object at 0x7f7675729c10>),\n",
       "                ('RF', RandomForestClassifier())])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rf_pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86519fbbec93c191aacc49d4c33e96a49fd6ef772decd8151fefe193caa932bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
